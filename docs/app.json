[{"name":"app.R","content":"source(\"ui.R\")\r\nsource(\"server.R\")\r\n\r\nshinyApp(ui, server)\r\n","type":"text"},{"name":"server.R","content":"library(shiny)\r\nlibrary(readxl)\r\n#library(DT)\r\n#library(openxlsx)\r\n#library(tools)\r\n\r\n# ------------------------------------------------------------\r\n# Load your semi-parametric Bayes implementation (external file)\r\n# ------------------------------------------------------------\r\n# This should define:\r\n#   fit_semiparam_bayes(), predict_semiparam_bayes()\r\n# and source its dependencies (kernel.R, categorical-kernel.R, standardize.R, etc.)\r\nsource(\"R/utils.R\")\r\nsource(\"R/kernel.R\")\r\nsource(\"R/categorical-kernel.R\")\r\nsource(\"R/standardize.R\")\r\n# source(\"R/boxcox.R\")  # 必要なら\r\nsource(\"R/semiparam_bayes.R\")\r\nsource(\"R/optimize_ucb.R\")\r\n\r\n# ------------------------------------------------------------\r\n# Shiny server\r\n# ------------------------------------------------------------\r\n\r\nshinyServer(function(input, output, session) {\r\n  \r\n  rv <- reactiveValues(\r\n    def = NULL,\r\n    data = NULL,\r\n    X_names = NULL,\r\n    Y_names = NULL,\r\n    y_focus = \"Y1\",\r\n    fit = NULL,     # will store list(fit=..., std=..., lambda=..., Xraw=..., yorg=...)\r\n    cand = NULL,\r\n    plot_df = NULL,\r\n    plot_meta = NULL,\r\n    error_msg = NULL\r\n  )\r\n  \r\n  fail <- function(msg) {\r\n    rv$error_msg <- msg\r\n    return(NULL)\r\n  }\r\n  \r\n  # error message for file upload\r\n  output$ui_error <- renderUI({\r\n    if (is.null(rv$error_msg) || rv$error_msg == \"\") return(NULL)\r\n    div(\r\n      style = \"background:#3b1218; border:1px solid #a33; color:#ffd6d6; padding:10px; border-radius:8px; margin-top:8px; font-size:13px;\",\r\n      strong(\"Error: \"),\r\n      span(rv$error_msg)\r\n    )\r\n  })\r\n  \r\n  \r\n  # ---- read Excel: Definition + Data ----\r\n  observeEvent(input$file_xlsx, {\r\n    req(input$file_xlsx)\r\n    rv$error_msg <- NULL\r\n    path <- input$file_xlsx$datapath\r\n    \r\n    sheets <- excel_sheets(path)\r\n    ns <- normalize_sheet_name(sheets)\r\n    \r\n    i_def  <- which(ns %in% c(\"definition\"))\r\n    i_data <- which(ns %in% c(\"data\"))\r\n    \r\n    if(length(i_def) != 1)  return (fail(\"Excel must contain a sheet named 'Definition'.\"))\r\n    if(length(i_data) != 1) return (fail(\"Excel must contain a sheet named 'Data'.\"))\r\n    \r\n    def_raw  <- read_excel(path, sheet = sheets[i_def[1]])\r\n    data_raw <- read_excel(path, sheet = sheets[i_data[1]])\r\n    \r\n    def <- as.data.frame(def_raw)\r\n    dat <- as.data.frame(data_raw)\r\n    \r\n    required_cols <- c(\"Parameter\", \"Min\", \"Standard\", \"Max\", \"Type\", \"Interval\", \"Purpose\")\r\n    \r\n    if (!all(required_cols %in% names(def))) {\r\n      return(fail(\"Definition sheet must contain columns: Parameter, Min, Standard, Max, Type, Purpose\"))\r\n    }\r\n    \r\n    def2 <- data.frame(\r\n      Parameter = as.character(def$Parameter),\r\n      Type      = as.character(def$Type),\r\n      Interval  = suppressWarnings(as.numeric(def$Interval)),\r\n      Purpose   = as.character(def$Purpose),\r\n      \r\n      # raw string (categorical対応)\r\n      Min_raw      = as.character(def$Min),\r\n      Standard_raw = as.character(def$Standard),\r\n      Max_raw      = as.character(def$Max),\r\n      \r\n      stringsAsFactors = FALSE\r\n    )\r\n    \r\n    def2 <- def2[!is.na(def2$Parameter) & trimws(def2$Parameter) != \"\", , drop = FALSE]\r\n    \r\n    # numeric版（continuous行だけ有効）\r\n    is_cont <- tolower(def2$Type) == \"continuous\"\r\n    def2$min_num      <- NA_real_\r\n    def2$standard_num <- NA_real_\r\n    def2$max_num      <- NA_real_\r\n    \r\n    def2$min_num[is_cont]      <- suppressWarnings(as.numeric(def2$Min_raw[is_cont]))\r\n    def2$standard_num[is_cont] <- suppressWarnings(as.numeric(def2$Standard_raw[is_cont]))\r\n    def2$max_num[is_cont]      <- suppressWarnings(as.numeric(def2$Max_raw[is_cont]))\r\n    \r\n    X_names <- def2$Parameter[grepl(\"^X\", def2$Parameter, ignore.case = TRUE)]\r\n    Y_names <- def2$Parameter[grepl(\"^Y\", def2$Parameter, ignore.case = TRUE)]\r\n    \r\n    if (length(X_names) < 1) return(fail(\"Definition must contain at least one X parameter (e.g., X1).\"))\r\n    if (length(Y_names) < 1) return(fail(\"Definition must contain at least one Y parameter (e.g., Y1).\"))\r\n    if (!(\"Y1\" %in% Y_names)) return(fail(\"First version expects Definition to include Y1.\"))\r\n    if (!(\"id\" %in% names(dat))) return(fail(\"Data sheet must contain column 'id'.\"))\r\n    if (!(all(X_names %in% names(dat)))) return(fail(\"Data sheet must contain all X columns defined in Definition.\"))\r\n    if (!(all(Y_names %in% names(dat)))) return(fail(\"Data sheet must contain all Y columns defined in Definition.\"))\r\n    \r\n    dat2 <- dat[, c(\"id\", X_names, Y_names), drop = FALSE]\r\n    dat2 <- na.omit(dat2)\r\n    dat2$id <- as.character(dat2$id)\r\n    \r\n    \r\n    X_cont <- def2$Parameter[tolower(def2$Type) == \"continuous\"  & grepl(\"^X\", def2$Parameter, ignore.case=TRUE)]\r\n    X_cat  <- def2$Parameter[tolower(def2$Type) == \"categorical\" & grepl(\"^X\", def2$Parameter, ignore.case=TRUE)]\r\n    \r\n    dat2 <- dat[, c(\"id\", X_names, Y_names), drop = FALSE]\r\n    dat2 <- na.omit(dat2)\r\n    dat2$id <- as.character(dat2$id)\r\n    \r\n    # continuousだけ numeric\r\n    for (nm in c(X_cont, Y_names)) dat2[[nm]] <- as.numeric(dat2[[nm]])\r\n    \r\n    # categoricalは factor/characterのまま（Excelから数字っぽく読まれても文字に戻す）\r\n    for (nm in X_cat) dat2[[nm]] <- as.character(dat2[[nm]])\r\n    \r\n    \r\n    rv$def <- def2\r\n    rv$data <- dat2\r\n    rv$X_cont <- X_cont\r\n    rv$X_cat  <- X_cat\r\n    rv$X_names <- X_names\r\n    rv$Y_names <- Y_names\r\n    rv$fit <- NULL\r\n    rv$cand <- NULL\r\n  })\r\n  \r\n  # ---- UI pieces ----\r\n  output$ui_sheet <- renderUI({ NULL })\r\n  output$ui_col_select <- renderUI({ NULL })\r\n  \r\n  output$ui_info <- renderUI({\r\n    req(rv$def, rv$X_names, rv$Y_names)\r\n    x_cont_txt <- paste(rv$X_cont, collapse = \", \")\r\n    x_cat_txt <- paste(rv$X_cat, collapse = \", \")\r\n    y_txt <- paste(rv$Y_names, collapse = \", \")\r\n    \r\n    y1_purpose <- rv$def$Purpose[rv$def$Parameter == \"Y1\"]\r\n    y1_purpose <- if (length(y1_purpose) == 0 || is.na(y1_purpose)) \"\" else y1_purpose[1]\r\n    \r\n    div(\r\n      tags$div(\"Input parameter:\"),\r\n      tags$div(paste0(\"Continuous: \", x_cont_txt)),\r\n      tags$div(paste0(\"Categorical: \", x_cat_txt)),\r\n      tags$br(),\r\n      tags$div(\"Output value:\"),\r\n      tags$div(paste0(\"Continuous: \", y_txt)),\r\n      tags$br(),\r\n      tags$div(paste0(\"Purpose (Y1): \", y1_purpose))\r\n    )\r\n  })\r\n  \r\n  # --- 1. Data Display -----\r\n  # output$tbl_uploaded_data <- renderTable({\r\n  #   req(rv$data)\r\n  #   \r\n  #   datatable(\r\n  #     rv$data,\r\n  #     rownames = FALSE,\r\n  #     options = list(\r\n  #       pageLength = 20,\r\n  #       scrollX = FALSE,\r\n  #       autoWidth = TRUE\r\n  #     )\r\n  #   )\r\n  # })\r\n  output$tbl_uploaded_data <- renderTable({\r\n    req(rv$data)\r\n    rv$data\r\n  }, striped = FALSE, bordered = TRUE, hover = TRUE)\r\n  \r\n  \r\n  # output$tbl_definition <- renderDT({\r\n  #   req(rv$def)\r\n  #   \r\n  #   datatable(\r\n  #     rv$def,\r\n  #     rownames = FALSE,\r\n  #     options = list(\r\n  #       paging = FALSE,\r\n  #       searching = FALSE,\r\n  #       info = FALSE,\r\n  #       autoWidth = TRUE\r\n  #     )\r\n  #   )\r\n  # })\r\n  output$tbl_definition <- renderTable({\r\n    req(rv$def)\r\n    rv$def[,c(-3,-2,-1)]\r\n  }, striped = FALSE, bordered = TRUE, hover = TRUE)\r\n  \r\n  \r\n  \r\n  \r\n  # ---- Fit model (button): use your semiparam Bayes ----\r\n  clamp_nonneg <- function(id, default = 0) {\r\n    observeEvent(input[[id]], {\r\n      val <- input[[id]]\r\n      if (is.null(val) || !is.finite(val) || val <= 0) {\r\n        updateNumericInput(session, id, value = default)\r\n      }\r\n    })\r\n  }\r\n  clamp_nonneg(\"hp1\", 1e-6)\r\n  clamp_nonneg(\"hp2\", 1e-6)\r\n  clamp_nonneg(\"hp3\", 1e-6)\r\n  clamp_nonneg(\"hp_sigma0\", 1e-6)\r\n  clamp_nonneg(\"hp_cat\", 0)\r\n  \r\n  do_fit <- function() {\r\n    req(rv$data, rv$X_names, rv$def)\r\n    \r\n    dat <- rv$data\r\n    \r\n    # --- split continuous / categorical from Definition ---\r\n    X_cont <- rv$def$Parameter[tolower(rv$def$Type) == \"continuous\" & rv$def$Parameter %in% rv$X_names]\r\n    X_cat  <- rv$def$Parameter[tolower(rv$def$Type) == \"categorical\" & rv$def$Parameter %in% rv$X_names]\r\n    \r\n    validate(need(length(X_cont) > 0, \"At least one continuous X is required for GP (Type='continuous').\"))\r\n    \r\n    # --- response ---\r\n    yorg <- as.numeric(dat[[\"Y1\"]])\r\n    \r\n    # Box-Cox (OFF for now)\r\n    lambda <- NULL\r\n    if (exists(\"fwd_y\", mode = \"function\")) {\r\n      y <- fwd_y(yorg, lambda = lambda)\r\n    } else {\r\n      y <- yorg\r\n    }\r\n    \r\n    # --- continuous matrix (numeric) ---\r\n    Xraw_cont <- as.matrix(dat[, X_cont, drop = FALSE])\r\n    storage.mode(Xraw_cont) <- \"double\"\r\n    \r\n    # --- categorical data.frame (character) ---\r\n    Z_cat <- NULL\r\n    if (length(X_cat) > 0) {\r\n      Z_cat <- as.data.frame(dat[, X_cat, drop = FALSE])\r\n      names(Z_cat) <- X_cat\r\n      for (nm in X_cat) Z_cat[[nm]] <- as.character(Z_cat[[nm]])\r\n    }\r\n    \r\n    # --- design matrices (continuous only) ---\r\n    X <- cbind(1, Xraw_cont)\r\n    Z <- Xraw_cont\r\n    \r\n    # --- standardize (continuous only) ---\r\n    std <- standardize_fit(X, Z, y, standardize_X = TRUE, intercept_col = 1L)\r\n    \r\n    # --- hyperparameters ---\r\n    # ---- ハイパーパラメータ取得（UIに無い場合はデフォルト） ----\r\n    sf2 <- if (is.null(input$hp1)) 1.0 else as.numeric(input$hp1)\r\n    ell <- as.numeric(input$hp2)\r\n    sigma2 <- as.numeric(input$hp3)\r\n    sigma_cat2 <- if (is.null(input$hp_cat)) 0.5 else as.numeric(input$hp_cat)\r\n    #sf2    <- as.numeric(input$hp1)\r\n    #ell    <- as.numeric(input$hp2)\r\n    #sigma2 <- as.numeric(input$hp3)\r\n    \r\n    validate(need(is.finite(sf2) && sf2 > 0, \"hp1 (sf2) must be > 0\"))\r\n    validate(need(is.finite(ell) && ell > 0, \"hp2 (ell) must be > 0\"))\r\n    validate(need(is.finite(sigma2) && sigma2 >= 0, \"hp3 (sigma2) must be >= 0\"))\r\n    \r\n    # categorical kernel variance (optional UI)\r\n    #sigma_cat2 <- 10\r\n    #if (!is.null(input$hp_cat) && is.finite(as.numeric(input$hp_cat))) {\r\n    #  sigma_cat2 <- as.numeric(input$hp_cat)\r\n    #}\r\n    \r\n    # --- prior on beta ---\r\n    p <- ncol(std$X)\r\n    mu0 <- rep(0, p)\r\n    Sigma0 <- diag(100, p)#default\r\n    if (!is.null(input$hp_sigma0) && is.finite(as.numeric(input$hp_sigma0))) {\r\n      Sigma0 <- diag(as.numeric(input$hp_sigma0),p)\r\n    }\r\n    \r\n    # --- fit ---\r\n    fit <- fit_semiparam_bayes(\r\n      y = std$y, X = std$X, Z = std$Z,\r\n      Z_cat = Z_cat,\r\n      mu0 = mu0, Sigma0 = Sigma0,\r\n      sigma2 = sigma2, ell = ell, sf2 = sf2,\r\n      sigma_cat2 = sigma_cat2\r\n    )\r\n    var_s <- sqrt(pmax(as.numeric(fit$eps_var_hat), 0))\r\n    y_pred <- destandardize_y(fit$y_hat, std)\r\n    var_pred <- destandardize_y_sd(var_s, std)\r\n    \r\n    # --- store wrapper ---\r\n    rv$fit <- list(\r\n      fit = fit,#standardizeされてる\r\n      std = std,\r\n      lambda = lambda,\r\n      X_cont = X_cont,\r\n      X_cat  = X_cat,\r\n      Xraw_cont = Xraw_cont,\r\n      Z_cat = Z_cat,\r\n      yorg = yorg,\r\n      y_pred = y_pred,\r\n      var_pred = var_pred\r\n    )\r\n  }\r\n  \r\n  observeEvent(input$btn_fit,   { do_fit() })\r\n  observeEvent(input$btn_refit, { do_fit() })\r\n  \r\n  # ---- Fitting info ----\r\n  output$fit_info <- renderPrint({\r\n    req(rv$fit)\r\n    fit <- rv$fit$fit\r\n    p <- length(fit$mu_beta)\r\n    \r\n    txt <- paste0(\r\n      \"Semi-parametric Bayesian regression: y = X beta + u + eps\\n\",\r\n      \"beta ~ N(mu0, Sigma0), u ~ N(0, K), eps ~ N(0, sigma2 I)\\n\",\r\n      \"\\n[Posterior beta | y]\\n\",\r\n      paste(sprintf(\"mu_beta[%d] = %.6f\", seq_len(p), fit$mu_beta), collapse = \"\\n\"),\r\n      \"\\n\\n[Hyperparameters]\\n\",\r\n      sprintf(\"sf2 (RBF scale) = %.4f\\n\", fit$sf2),\r\n      sprintf(\"ell (lengthscale) = %.4f\\n\", fit$ell),\r\n      sprintf(\"sigma2 (noise var) = %.6f\\n\", fit$sigma2),\r\n      sprintf(\"mu0 (beta prior mean) = %.4f\\n\", fit$mu0[1]),\r\n      sprintf(\"Sigma0 (beta prior var.) = %.4f\\n\", fit$Sigma0[1]),\r\n      sprintf(\"sigma_cat (prior var. of categorical param.) = %.6f\\n\", fit$sigma_cat2),\r\n      \"\\n[Residuals]\\n\",\r\n      sprintf(\"eps var.= %.4f, RMSE=%.4f\", fit$eps_var_hat, fit$rmse_total)\r\n    )\r\n    \r\n    cat(txt)\r\n  })\r\n  \r\n  \r\n  # ---- Model tab: Pred vs Obs (training points) ----\r\n  output$plot_pred_vs_obs <- renderPlot({\r\n    req(rv$fit)\r\n    fit <- rv$fit$fit\r\n    std <- rv$fit$std\r\n    lambda <- rv$fit$lambda\r\n    \r\n    # predict at training points (standardized space)\r\n    pred_s <- predict_semiparam_bayes(\r\n      fit, Xnew = fit$X, Znew = fit$Z, Z_cat_new = fit$Z_cat,\r\n      return_components = FALSE\r\n    )\r\n    \r\n    yhat_s <- pred_s$mean\r\n    # back to original scale (if functions exist)\r\n    if (exists(\"destandardize_y\", mode = \"function\")) {\r\n      yhat <- destandardize_y(yhat_s, std)\r\n    } else {\r\n      yhat <- yhat_s\r\n    }\r\n    if (exists(\"inv_y\", mode = \"function\")) {\r\n      yhat <- inv_y(yhat, lambda = lambda)\r\n    }\r\n    \r\n    yobs <- rv$fit$yorg\r\n    \r\n    rng <- range(c(yobs, yhat), na.rm = TRUE)\r\n    par(mar = c(4,4,1,1))\r\n    plot(yobs, yhat, pch = 19,\r\n         xlab = \"Obtained Y1\",\r\n         ylab = \"Prediction Y1\",\r\n         xlim = rng, ylim = rng)\r\n    abline(0, 1, lwd = 2)\r\n  })\r\n  \r\n  # ---- Analyze tab: choose X1 ----\r\n  output$ui_x1_select <- renderUI({\r\n    req(rv$X_names)\r\n    selectInput(\"x1\", \"Select input (X1)\", choices = rv$X_names, selected = rv$X_names[[1]])\r\n  })\r\n  \r\n  output$ui_x12_select <- renderUI({\r\n    req(rv$X_names)\r\n    \r\n    fluidRow(\r\n      column(\r\n        6,\r\n        selectInput(\"x1\",\r\n                    \"X (horizontal)\",\r\n                    choices = rv$X_names,\r\n                    selected = rv$X_names[[1]])\r\n      ),\r\n      column(\r\n        6,\r\n        selectInput(\"x2\",\r\n                    \"X (vertical)\",\r\n                    choices = rv$X_names,\r\n                    selected = rv$X_names[[1]])\r\n      )\r\n    )\r\n  })\r\n  \r\n  \r\n  \r\n  #helper\r\n  get_levels <- function(var) {\r\n    r <- rv$def[rv$def$Parameter == var, , drop = FALSE]\r\n    if (nrow(r) == 0) return(character(0))\r\n    # Definitionでは Min/Standard/Max の raw にレベル候補が入ってる想定\r\n    cand <- c(r$Min_raw[1], r$Standard_raw[1], r$Max_raw[1])\r\n    cand <- unique(trimws(as.character(cand)))\r\n    cand <- cand[!is.na(cand) & cand != \"\"]\r\n    cand\r\n  }\r\n  \r\n  get_fix_value <- function(var) {\r\n    r <- rv$def[rv$def$Parameter == var, , drop = FALSE]\r\n    if (nrow(r) == 0) return(NA)\r\n    t <- tolower(trimws(as.character(r$Type[1])))\r\n    if (t == \"continuous\") {\r\n      v <- suppressWarnings(as.numeric(r$standard_num[1]))\r\n      if (!is.finite(v)) v <- suppressWarnings(as.numeric(r$min_num[1]))\r\n      if (!is.finite(v)) v <- 0\r\n      return(v)\r\n    } else {\r\n      v <- as.character(r$Standard_raw[1])\r\n      if (is.na(v) || v == \"\") v <- as.character(r$Min_raw[1])\r\n      return(v)\r\n    }\r\n  }\r\n  \r\n  \r\n  # ---- Plot Y1 vs X1, X2 ----\r\n  output$plot_1d <- renderPlot({\r\n    req(rv$fit, rv$def, rv$X_names, input$x1)\r\n    \r\n    fit <- rv$fit$fit\r\n    std <- rv$fit$std\r\n    \r\n    def_all <- rv$def\r\n    Xnames  <- rv$X_names\r\n    \r\n    X_cont <- rv$fit$X_cont\r\n    X_cat  <- rv$fit$X_cat\r\n    \r\n    x1 <- input$x1\r\n    x2 <- if (!is.null(input$x2) && input$x2 != \"None\") input$x2 else x1  # 未選択は同一扱い\r\n    \r\n    # ---------- helpers ----------\r\n    get_type <- function(xn) {\r\n      rr <- def_all[def_all$Parameter == xn, , drop = FALSE]\r\n      if (nrow(rr) == 0) return(NA_character_)\r\n      tolower(as.character(rr$Type[1]))\r\n    }\r\n    \r\n    get_fix_value <- function(xn) {\r\n      rr <- def_all[def_all$Parameter == xn, , drop = FALSE]\r\n      tp <- tolower(as.character(rr$Type[1]))\r\n      \r\n      if (tp == \"continuous\") {\r\n        v <- as.numeric(rr$standard[1])\r\n        if (!is.finite(v)) {\r\n          j <- match(xn, X_cont)\r\n          if (!is.na(j) && !is.null(rv$fit$Xraw_cont)) {\r\n            v <- median(as.numeric(rv$fit$Xraw_cont[, j]), na.rm = TRUE)\r\n          } else v <- 0\r\n        }\r\n        return(v)\r\n      }\r\n      \r\n      if (tp == \"categorical\") {\r\n        v <- as.character(rr$standard[1])\r\n        if (is.na(v) || v == \"\") v <- as.character(rr$min[1])\r\n        if (is.na(v) || v == \"\") {\r\n          if (!is.null(rv$fit$Z_cat) && xn %in% names(rv$fit$Z_cat)) {\r\n            tab <- table(rv$fit$Z_cat[[xn]])\r\n            if (length(tab) > 0) v <- names(which.max(tab))\r\n          }\r\n        }\r\n        return(v)\r\n      }\r\n      \r\n      NA\r\n    }\r\n    \r\n    get_levels <- function(xn) {\r\n      # prefer training levels\r\n      if (!is.null(rv$fit$Z_cat) && xn %in% names(rv$fit$Z_cat)) {\r\n        lv <- unique(as.character(rv$fit$Z_cat[[xn]]))\r\n        lv <- lv[!is.na(lv) & lv != \"\"]\r\n        if (length(lv) > 0) return(lv)\r\n      }\r\n      rr <- def_all[def_all$Parameter == xn, , drop = FALSE]\r\n      lv <- unique(c(as.character(rr$min[1]), as.character(rr$max[1]), as.character(rr$standard[1])))\r\n      lv <- lv[!is.na(lv) & lv != \"\"]\r\n      lv\r\n    }\r\n    \r\n    get_levels_ordered <- function(cat_name) {\r\n      def_row <- rv$def[rv$def$Parameter == cat_name, , drop = FALSE]\r\n      if (nrow(def_row) == 0) return(character(0))\r\n      \r\n      lv <- c(def_row$Min_raw[1], def_row$Standard_raw[1], def_row$Max_raw[1])\r\n      lv <- lv[!is.na(lv) & trimws(lv) != \"\"]\r\n      lv <- unique(as.character(lv))\r\n      \r\n      # （任意）training にだけ出るレベルも最後に足す\r\n      if (!is.null(rv$fit$Z_cat) && cat_name %in% names(rv$fit$Z_cat)) {\r\n        lv_tr <- unique(as.character(rv$fit$Z_cat[[cat_name]]))\r\n        lv <- unique(c(lv, lv_tr))\r\n      }\r\n      \r\n      lv\r\n    }\r\n    \r\n    get_grid_cont <- function(xn, max_n = 20, default_n = 100) {\r\n      rr <- def_all[def_all$Parameter == xn, , drop = FALSE]\r\n      mn <- as.numeric(rr$min[1]); mx <- as.numeric(rr$max[1])\r\n      it <- as.numeric(rr$Interval[1])\r\n      \r\n      j <- match(xn, X_cont)\r\n      if (!is.finite(mn) || !is.finite(mx) || mx <= mn) {\r\n        if (!is.na(j) && !is.null(rv$fit$Xraw_cont)) {\r\n          mn <- min(rv$fit$Xraw_cont[, j], na.rm = TRUE)\r\n          mx <- max(rv$fit$Xraw_cont[, j], na.rm = TRUE)\r\n        }\r\n      }\r\n      \r\n      if (is.na(it) || !is.finite(it) || it <= 0) {\r\n        seq(mn, mx, length.out = default_n)\r\n      } else {\r\n        make_grid_1d(mn, mx, it, max_n = max_n)\r\n      }\r\n    }\r\n    \r\n    pred_wrap <- function(Xcont_new, Zcat_new) {\r\n      Xcont_new <- as.matrix(Xcont_new)\r\n      storage.mode(Xcont_new) <- \"double\"\r\n      \r\n      Xnew <- cbind(1, Xcont_new)\r\n      Znew <- Xcont_new\r\n      \r\n      new_s <- standardize_apply(Xnew, Znew, std)\r\n      \r\n      pr <- predict_semiparam_bayes(\r\n        fit,\r\n        Xnew = new_s$X,\r\n        Znew = new_s$Z,\r\n        Z_cat_new = Zcat_new,\r\n        return_components = TRUE\r\n      )\r\n      \r\n      mu_s <- as.numeric(pr$mean)#予測平均\r\n      sd_s <- sqrt(pmax(as.numeric(pr$var_total), 0))\r\n      \r\n      mu <- destandardize_y(mu_s, std)\r\n      sd <- destandardize_y_sd(sd_s, std)\r\n      \r\n      list(mu = as.numeric(mu), sd = as.numeric(sd))\r\n    }\r\n    \r\n    # ---------- types ----------\r\n    t1 <- get_type(x1)\r\n    t2 <- get_type(x2)\r\n    validate(need(!is.na(t1) && !is.na(t2), \"Type in Definition must be 'continuous' or 'categorical'.\"))\r\n    \r\n    # training y (for overlay)\r\n    y_obs <- as.numeric(rv$fit$yorg)\r\n    \r\n    # ========= CASE 1 =========\r\n    # X1(continuous) == X1(continuous) : 1D line plot\r\n    if (t1 == \"continuous\" && t2 == \"continuous\" && x1 == x2) {\r\n      \r\n      xg <- get_grid_cont(x1, max_n = 20, default_n = 100)\r\n      \r\n      Xcont_new <- matrix(NA_real_, nrow = length(xg), ncol = length(X_cont))\r\n      colnames(Xcont_new) <- X_cont\r\n      for (nm in X_cont) Xcont_new[, nm] <- get_fix_value(nm)\r\n      Xcont_new[, x1] <- xg\r\n      \r\n      Zcat_new <- NULL\r\n      if (length(X_cat) > 0) {\r\n        Zcat_new <- as.data.frame(matrix(NA_character_, nrow = length(xg), ncol = length(X_cat)))\r\n        names(Zcat_new) <- X_cat\r\n        for (nm in X_cat) Zcat_new[[nm]] <- as.character(get_fix_value(nm))\r\n      }\r\n      \r\n      pr <- pred_wrap(Xcont_new, Zcat_new)\r\n      mu <- pr$mu; sd <- pr$sd\r\n      lo <- mu - sd; hi <- mu + sd\r\n      \r\n      ok <- is.finite(xg) & is.finite(mu) & is.finite(lo) & is.finite(hi)\r\n      validate(need(any(ok), \"No finite predictions.\"))\r\n      \r\n      # overlay training points (if available)\r\n      jx <- match(x1, X_cont)\r\n      x_obs <- if (!is.na(jx)) as.numeric(rv$fit$Xraw_cont[, jx]) else NULL\r\n      \r\n      ylim <- range(c(lo[ok], hi[ok], y_obs), na.rm = TRUE)\r\n      if (!all(is.finite(ylim))) ylim <- c(0, 1)\r\n      \r\n      df_out <- data.frame(\r\n        x = xg,\r\n        y = mu\r\n      )\r\n      # 2次利用したいなら誤差も一緒に（任意）\r\n      # df_out$y_lo <- lo\r\n      # df_out$y_hi <- hi\r\n      rv$plot_df <- df_out\r\n      rv$plot_meta <- list(case = 1, x1 = x1, x2 = x2, type = \"1d\")\r\n      \r\n      \r\n      \r\n      par(mar = c(4,4,1,1))\r\n      plot(xg[ok], mu[ok], type = \"l\", lwd = 2, xlab = x1, ylab = \"Y1\", ylim = ylim)\r\n      lines(xg[ok], lo[ok], lty = 2)\r\n      lines(xg[ok], hi[ok], lty = 2)\r\n      if (!is.null(x_obs)) points(x_obs, y_obs, pch = 19)\r\n      return(invisible())\r\n    }\r\n    \r\n    # ========= CASE 2 =========\r\n    # X1(continuous) != X2(continuous) : 2D contour plot\r\n    if (t1 == \"continuous\" && t2 == \"continuous\" && x1 != x2) {\r\n      \r\n      x1g <- get_grid_cont(x1, max_n = 10, default_n = 20)\r\n      x2g <- get_grid_cont(x2, max_n = 10, default_n = 20)\r\n      \r\n      grid <- expand.grid(x1g, x2g)\r\n      names(grid) <- c(x1, x2)\r\n      \r\n      Xcont_new <- matrix(NA_real_, nrow = nrow(grid), ncol = length(X_cont))\r\n      colnames(Xcont_new) <- X_cont\r\n      for (nm in X_cont) Xcont_new[, nm] <- get_fix_value(nm)\r\n      Xcont_new[, x1] <- grid[[x1]]\r\n      Xcont_new[, x2] <- grid[[x2]]\r\n      \r\n      Zcat_new <- NULL\r\n      if (length(X_cat) > 0) {\r\n        Zcat_new <- as.data.frame(matrix(NA_character_, nrow = nrow(grid), ncol = length(X_cat)))\r\n        names(Zcat_new) <- X_cat\r\n        for (nm in X_cat) Zcat_new[[nm]] <- as.character(get_fix_value(nm))\r\n      }\r\n      \r\n      pr <- pred_wrap(Xcont_new, Zcat_new)\r\n      mu <- pr$mu\r\n      ok <- is.finite(mu)\r\n      validate(need(any(ok), \"No finite predictions.\"))\r\n      \r\n      zmat <- matrix(mu, nrow = length(x1g), ncol = length(x2g), byrow = FALSE)\r\n      \r\n      #保存用\r\n      df_out <- data.frame(\r\n        x1 = grid[[x1]],\r\n        x2 = grid[[x2]],\r\n        y  = mu\r\n      )\r\n      names(df_out)[1:2] <- c(x1, x2)\r\n      rv$plot_df <- df_out\r\n      rv$plot_meta <- list(case = 2, x1 = x1, x2 = x2, type = \"2d\")\r\n      \r\n      \r\n      cols <- colorRampPalette(c(\"#0d0887\", \"#6a00a8\", \"#b12a90\", \"#e16462\", \"#fca636\", \"#f0f921\"))(50)\r\n      \r\n      par(mar = c(4,4,1,1))\r\n      image(x1g, x2g, zmat, col = cols, xlab = x1, ylab = x2)\r\n      contour(x1g, x2g, zmat, add = TRUE)\r\n      \r\n      # training points overlay\r\n      j1 <- match(x1, X_cont)\r\n      j2 <- match(x2, X_cont)\r\n      if (!is.na(j1) && !is.na(j2)) {\r\n        points(rv$fit$Xraw_cont[, j1], rv$fit$Xraw_cont[, j2], pch = 19, col = \"white\")\r\n      }\r\n      \r\n      return(invisible())\r\n    }\r\n    \r\n    # ========= CASE 3 =========\r\n    # continuous + categorical:\r\n    #   x-axis = continuous, y-axis = Y1, legend = categorical\r\n    if ((t1 == \"continuous\" && t2 == \"categorical\" && x1 != x2) ||\r\n        (t1 == \"categorical\" && t2 == \"continuous\" && x1 != x2)) {\r\n      \r\n      x_cont <- if (t1 == \"continuous\") x1 else x2\r\n      x_cat  <- if (t1 == \"categorical\") x1 else x2\r\n      \r\n      xg <- get_grid_cont(x_cont, max_n = 20, default_n = 100)\r\n      \r\n      def2 <- rv$def\r\n      lv <- get_levels_ordered(x_cat)\r\n      validate(need(length(lv) >= 1, paste0(\"No categorical levels for \", x_cat)))\r\n      \r\n      m <- length(xg) * length(lv)\r\n      \r\n      # --- continuous matrix for prediction (continuous vars only) ---\r\n      Xcont_new <- matrix(NA_real_, nrow = m, ncol = length(X_cont))\r\n      colnames(Xcont_new) <- X_cont\r\n      for (nm in X_cont) Xcont_new[, nm] <- get_fix_value(nm)\r\n      Xcont_new[, x_cont] <- rep(xg, times = length(lv))\r\n      \r\n      # --- categorical new (all fixed, but x_cat varies over levels) ---\r\n      Zcat_new <- NULL\r\n      if (length(X_cat) > 0) {\r\n        Zcat_new <- as.data.frame(matrix(NA_character_, nrow = m, ncol = length(X_cat)))\r\n        names(Zcat_new) <- X_cat\r\n        for (nm in X_cat) Zcat_new[[nm]] <- as.character(get_fix_value(nm))\r\n        Zcat_new[[x_cat]] <- rep(as.character(lv), each = length(xg))\r\n      } else {\r\n        validate(need(FALSE, \"Model has no categorical inputs but one axis is categorical.\"))\r\n      }\r\n      \r\n      # --- prediction (mean only) ---\r\n      pr <- pred_wrap(Xcont_new, Zcat_new)  # pr$mu, pr$sd を返す想定\r\n      mu <- pr$mu\r\n      ok <- is.finite(mu)\r\n      validate(need(any(ok), \"No finite predictions.\"))\r\n      \r\n      #保存用\r\n      df_out <- data.frame(\r\n        x = rep(xg, times = length(lv)),\r\n        cat = rep(as.character(lv), each = length(xg)),\r\n        y = mu\r\n      )\r\n      names(df_out)[1] <- x_cont\r\n      names(df_out)[2] <- x_cat\r\n      \r\n      rv$plot_df <- df_out\r\n      rv$plot_meta <- list(case = 3, x1 = x1, x2 = x2, type = \"1d+cat\")\r\n      \r\n      \r\n      ylim <- range(c(mu[ok], y_obs), na.rm = TRUE)\r\n      if (!all(is.finite(ylim))) ylim <- c(0, 1)\r\n      \r\n      par(mar = c(4,4,1,1))\r\n      plot(xg, numeric(length(xg)), type = \"n\", xlab = x_cont, ylab = \"Predicted Y1 (mean)\", ylim = ylim)\r\n      \r\n      # --- draw one line per categorical level ---\r\n      for (k in seq_along(lv)) {\r\n        idx <- ((k - 1) * length(xg) + 1):(k * length(xg))\r\n        lines(xg, mu[idx], lwd = 2, col=k)\r\n      }\r\n      legend(\"topleft\", legend = lv, lwd = 2, bty = \"n\", title = x_cat, col = seq_along(lv))\r\n      \r\n      # --- training points overlay (optional; x-axis=continuous only) ---\r\n      jx <- match(x_cont, X_cont)\r\n      if (!is.na(jx) && !is.null(rv$fit$Xraw_cont)) {\r\n        points(rv$fit$Xraw_cont[, jx], y_obs, pch = 19)\r\n      }\r\n      \r\n      return(invisible())\r\n    }\r\n    \r\n    \r\n    # ========= CASE 4 =========\r\n    # X1(categorical) == X1(categorical) : \r\n    # scatter plot + error bars\r\n    \r\n    if (t1 == \"categorical\" && t2 == \"categorical\" && x1 == x2) {\r\n      \r\n      lv <- get_levels(x1)\r\n      validate(need(length(lv) >= 1, \"No categorical levels.\"))\r\n      \r\n      # ---- order: min, standard, max ----\r\n      defx <- rv$def[rv$def$Parameter == x1, , drop = FALSE]\r\n      lv_order <- unique(c(defx$Min_raw, defx$Standard_raw, defx$Max_raw))\r\n      lv_order <- lv_order[lv_order %in% lv]\r\n      lv_other <- setdiff(lv, lv_order)\r\n      lv <- c(lv_order, lv_other)\r\n      \r\n      n_lv <- length(lv)\r\n      \r\n      # ---- build prediction points ----\r\n      Xcont_new <- matrix(NA_real_, nrow = n_lv, ncol = length(X_cont))\r\n      colnames(Xcont_new) <- X_cont\r\n      \r\n      for (nm in X_cont) {\r\n        Xcont_new[, nm] <- get_fix_value(nm)\r\n      }\r\n      \r\n      Zcat_new <- as.data.frame(matrix(NA_character_, nrow = n_lv, ncol = length(X_cat)))\r\n      names(Zcat_new) <- X_cat\r\n      \r\n      for (nm in X_cat) {\r\n        Zcat_new[[nm]] <- as.character(get_fix_value(nm))\r\n      }\r\n      \r\n      Zcat_new[[x1]] <- as.character(lv)\r\n      \r\n      # ---- prediction ----\r\n      pr <- pred_wrap(Xcont_new, Zcat_new)\r\n      mu <- pr$mu\r\n      sd <- pr$sd\r\n      ok <- is.finite(mu) & is.finite(sd)\r\n      validate(need(any(ok), \"No finite predictions.\"))\r\n      \r\n      #保存用\r\n      df_out <- data.frame(\r\n        x = as.character(lv),\r\n        y = mu\r\n      )\r\n      names(df_out)[1] <- x1\r\n      \r\n      # 任意：エラーバーも保存したいなら\r\n      # df_out$sd <- sd\r\n      # df_out$y_lo <- mu - sd\r\n      # df_out$y_hi <- mu + sd\r\n      \r\n      rv$plot_df <- df_out\r\n      rv$plot_meta <- list(case = 4, x1 = x1, x2 = x2, type = \"cat\")\r\n      \r\n      \r\n      \r\n      ylim <- range(c((mu - sd)[ok], (mu + sd)[ok], y_obs), na.rm = TRUE)\r\n      if (!all(is.finite(ylim))) ylim <- c(0, 1)\r\n      \r\n      xpos <- seq_along(lv)\r\n      \r\n      par(mar = c(6,4,1,1))\r\n      plot(xpos, mu,\r\n           type = \"n\",\r\n           xaxt = \"n\",\r\n           xlab = x1,\r\n           ylab = \"Predicted Y1\",\r\n           ylim = ylim)\r\n      \r\n      axis(1, at = xpos, labels = lv, las = 2)\r\n      \r\n      # ---- error bars ----\r\n      arrows(xpos,\r\n             mu - sd,\r\n             xpos,\r\n             mu + sd,\r\n             angle = 90,\r\n             code = 3,\r\n             length = 0.05)\r\n      \r\n      # ---- predicted mu (point) ----\r\n      points(xpos, mu, pch = 1, cex = 1.2)\r\n      \r\n      # ---- training data overlay (jitter) ----\r\n      if (!is.null(rv$fit$Z_cat) && x1 %in% names(rv$fit$Z_cat)) {\r\n        \r\n        x_tr <- as.character(rv$fit$Z_cat[[x1]])\r\n        idx  <- match(x_tr, lv)\r\n        ok2  <- !is.na(idx) & is.finite(y_obs)\r\n        \r\n        if (any(ok2)) {\r\n          points(\r\n            jitter(idx[ok2], amount = 0.03),\r\n            y_obs[ok2],\r\n            pch = 19,\r\n            col = rgb(0,0,0,0.7)\r\n          )\r\n        }\r\n      }\r\n      \r\n      return(invisible())\r\n    }\r\n    \r\n    \r\n    # ========= CASE 5 =========\r\n    # X1(categorical) != X2(categorical) : Not available\r\n    if (t1 == \"categorical\" && t2 == \"categorical\" && x1 != x2) {\r\n      rv$plot_df <- NULL\r\n      rv$plot_meta <- list(case = 5, x1 = x1, x2 = x2, type = \"na\")\r\n      \r\n      par(mar = c(4,4,1,1))\r\n      plot.new()\r\n      text(0.5, 0.5, \"Not available: categorical vs categorical (different variables)\", cex = 1.1)\r\n      return(invisible())\r\n    }\r\n    \r\n    # fallback\r\n    par(mar = c(4,4,1,1))\r\n    plot.new()\r\n    text(0.5, 0.5, \"Unsupported combination. Check Definition Type.\", cex = 1.1)\r\n  })\r\n  \r\n  \r\n  #-------------------------------------------------------------------  \r\n  # Optimize tab: generate candidates from Definition \r\n  #-------------------------------------------------------------------\r\n  #-------------------------------------------------------------------\r\n  # Optimize tab: generate candidates from Definition (FULL VERSION)\r\n  #-------------------------------------------------------------------\r\n  output$ui_btn_suggest <- renderUI({\r\n    req(rv$fit)\r\n    actionButton(\r\n      \"btn_suggest\",\r\n      \"Suggest next experiments\",\r\n      class = \"btn-wide btn-primary\"\r\n    )\r\n  })\r\n  \r\n  observeEvent(input$btn_suggest, {\r\n    \r\n    req(rv$def, rv$X_names, rv$fit)\r\n    \r\n    rv$error_msg <- NULL\r\n    \r\n    def2     <- rv$def\r\n    Xnames   <- rv$X_names\r\n    fit_wrap <- rv$fit\r\n    \r\n    # --- normalize Type ---\r\n    def2$Type <- tolower(trimws(def2$Type))\r\n    \r\n    # -----------------------------------------------------------\r\n    # helper: categorical level extraction\r\n    # -----------------------------------------------------------\r\n    get_cat_levels <- function(def2, nm, data_df = NULL) {\r\n      \r\n      row_def <- def2[def2$Parameter == nm, , drop = FALSE]\r\n      if (nrow(row_def) == 0) return(character(0))\r\n      \r\n      levs <- unique(na.omit(trimws(c(\r\n        row_def$Min_raw[1],\r\n        row_def$Standard_raw[1],\r\n        row_def$Max_raw[1]\r\n      ))))\r\n      \r\n      levs <- levs[levs != \"\"]\r\n      \r\n      if (length(levs) == 0 &&\r\n          !is.null(data_df) &&\r\n          nm %in% names(data_df)) {\r\n        \r\n        levs <- unique(na.omit(as.character(data_df[[nm]])))\r\n      }\r\n      \r\n      levs\r\n    }\r\n    \r\n    # -----------------------------------------------------------\r\n    # build candidate list per variable\r\n    # -----------------------------------------------------------\r\n    cand_list <- vector(\"list\", length(Xnames))\r\n    names(cand_list) <- Xnames\r\n    \r\n    for (nm in Xnames) {\r\n      \r\n      row_def <- def2[def2$Parameter == nm, , drop = FALSE]\r\n      if (nrow(row_def) == 0) {\r\n        rv$error_msg <- paste(\"Definition missing for\", nm)\r\n        return(NULL)\r\n      }\r\n      \r\n      if (row_def$Type[1] == \"continuous\") {\r\n        \r\n        mn <- row_def$min_num[1]\r\n        mx <- row_def$max_num[1]\r\n        h  <- row_def$Interval[1]\r\n        \r\n        if (!is.finite(mn) || !is.finite(mx) || mx <= mn) {\r\n          mn <- min(rv$data[[nm]], na.rm = TRUE)\r\n          mx <- max(rv$data[[nm]], na.rm = TRUE)\r\n        }\r\n        \r\n        if (is.na(h) || !is.finite(h) || h <= 0) {\r\n          cand_list[[nm]] <- seq(mn, mx, length.out = 21)\r\n        } else {\r\n          cand_list[[nm]] <- seq(mn, mx, by = h)\r\n          if (length(cand_list[[nm]]) < 2)\r\n            cand_list[[nm]] <- c(mn, mx)\r\n        }\r\n        \r\n      } else if (row_def$Type[1] == \"categorical\") {\r\n        \r\n        levs <- get_cat_levels(def2, nm, rv$data)\r\n        \r\n        if (length(levs) == 0) {\r\n          rv$error_msg <- paste(\"No levels defined for categorical variable\", nm)\r\n          return(NULL)\r\n        }\r\n        \r\n        cand_list[[nm]] <- levs\r\n        \r\n      } else {\r\n        rv$error_msg <- paste(\"Unknown Type for\", nm)\r\n        return(NULL)\r\n      }\r\n    }\r\n    \r\n    # -----------------------------------------------------------\r\n    # full combination count\r\n    # -----------------------------------------------------------\r\n    n_all <- prod(vapply(cand_list, length, integer(1)))\r\n    \r\n    if (n_all <= 100) {\r\n      \r\n      grid_df <- expand.grid(\r\n        cand_list,\r\n        KEEP.OUT.ATTRS = FALSE,\r\n        stringsAsFactors = FALSE\r\n      )\r\n      \r\n    } else {\r\n      \r\n      set.seed(1)\r\n      \r\n      grid_df <- data.frame(matrix(nrow = 100, ncol = length(Xnames)))\r\n      names(grid_df) <- Xnames\r\n      \r\n      for (nm in Xnames) {\r\n        vv <- cand_list[[nm]]\r\n        grid_df[[nm]] <- sample(vv, size = 100, replace = TRUE)\r\n      }\r\n    }\r\n    \r\n    # -----------------------------------------------------------\r\n    # split continuous / categorical\r\n    # -----------------------------------------------------------\r\n    X_cont <- def2$Parameter[def2$Type == \"continuous\" &\r\n                               def2$Parameter %in% Xnames]\r\n    \r\n    X_cat  <- def2$Parameter[def2$Type == \"categorical\" &\r\n                               def2$Parameter %in% Xnames]\r\n    \r\n    # ---- continuous part ----\r\n    if (length(X_cont) > 0) {\r\n      Xnew_cont <- as.matrix(grid_df[, X_cont, drop = FALSE])\r\n      storage.mode(Xnew_cont) <- \"double\"\r\n    } else {\r\n      Xnew_cont <- matrix(numeric(0),\r\n                          nrow = nrow(grid_df),\r\n                          ncol = 0)\r\n    }\r\n    \r\n    Xnew <- cbind(1, Xnew_cont)\r\n    Znew <- Xnew_cont\r\n    \r\n    # ---- categorical part ----\r\n    Z_cat_new <- NULL\r\n    if (length(X_cat) > 0) {\r\n      Z_cat_new <- as.data.frame(grid_df[, X_cat, drop = FALSE])\r\n      for (nm in X_cat)\r\n        Z_cat_new[[nm]] <- as.character(Z_cat_new[[nm]])\r\n    }\r\n    \r\n    # -----------------------------------------------------------\r\n    # standardize (continuous only)\r\n    # -----------------------------------------------------------\r\n    new_s <- tryCatch(\r\n      standardize_apply(Xnew, Znew, fit_wrap$std),\r\n      error = function(e) {\r\n        rv$error_msg <- paste(\"Standardization failed:\", e$message)\r\n        return(NULL)\r\n      }\r\n    )\r\n    \r\n    if (is.null(new_s)) return(NULL)\r\n    \r\n    # -----------------------------------------------------------\r\n    # prediction\r\n    # -----------------------------------------------------------\r\n    pred <- tryCatch(\r\n      predict_semiparam_bayes(\r\n        fit_wrap$fit,\r\n        Xnew = new_s$X,\r\n        Znew = new_s$Z,\r\n        Z_cat_new = Z_cat_new,\r\n        return_components = TRUE\r\n      ),\r\n      error = function(e) {\r\n        rv$error_msg <- paste(\"Prediction failed:\", e$message)\r\n        return(NULL)\r\n      }\r\n    )\r\n    \r\n    if (is.null(pred)) return(NULL)\r\n    \r\n    mu_s <- pred$mean\r\n    sd_s <- sqrt(pmax(pred$var_total, 0))\r\n    mu <- destandardize_y(mu_s, fit_wrap$std)\r\n    sd <- destandardize_y_sd(sd_s, fit_wrap$std)\r\n    \r\n    # -----------------------------------------------------------\r\n    # UCB\r\n    # -----------------------------------------------------------\r\n    defY1 <- def2[def2$Parameter == \"Y1\", , drop = FALSE]\r\n    purpose_y1 <- defY1$Purpose[1]\r\n    if (is.na(purpose_y1) || purpose_y1 == \"\")\r\n      purpose_y1 <- \">=\"\r\n    \r\n    kappa <- 2.0\r\n    \r\n    ucb_score <- function(mu, sd, purpose, kappa) {\r\n      if (purpose %in% c(\">=\", \"max\", \"maximize\")) {\r\n        return(mu + kappa * sd)\r\n      } else {\r\n        return(-mu + kappa * sd)\r\n      }\r\n    }\r\n    \r\n    ucb <- ucb_score(mu, sd, purpose_y1, kappa)\r\n    \r\n    # -----------------------------------------------------------\r\n    # assemble result table\r\n    # -----------------------------------------------------------\r\n    result <- grid_df\r\n    result$`Pred mean Y1` <- mu\r\n    result$`Pred sd Y1`   <- sd\r\n    result$`UCB(Y1)`      <- ucb\r\n    \r\n    result <- result[order(result$`UCB(Y1)`, decreasing = TRUE), , drop = FALSE]\r\n    result <- head(result, 10)\r\n    \r\n    num_cols <- names(result)[sapply(result, is.numeric)]\r\n    for (nm in num_cols)\r\n      result[[nm]] <- round(result[[nm]], 4)\r\n    rv$cand <- result\r\n    rv$cand <- cbind(\r\n      Candidate = paste0(\"cand\", seq_len(nrow(rv$cand))),\r\n      rv$cand\r\n    )\r\n  })\r\n  \r\n  \r\n  # output$tbl_candidates <- renderDT({\r\n  #   req(rv$cand)\r\n  #   datatable(\r\n  #     rv$cand,\r\n  #     rownames = FALSE,\r\n  #     options = list(\r\n  #       pageLength = 10,\r\n  #       scrollX = FALSE,\r\n  #       autoWidth = TRUE\r\n  #     )\r\n  #   )\r\n  # })\r\n  output$tbl_candidates <- renderTable({\r\n    req(rv$cand)\r\n    head(rv$cand, 20)     # 表が長いと重いので上限推奨\r\n  }, striped = FALSE, bordered = TRUE, hover = TRUE)\r\n  \r\n  # ---- Save report ----\r\n  # output$btn_save <- downloadHandler(\r\n  #   filename = function() {\r\n  #     req(input$file_xlsx)\r\n  #     base <- sub(\"\\\\.xlsx$\", \"\", input$file_xlsx$name, ignore.case = TRUE)\r\n  #     paste0(base, \"_\", format(Sys.time(), \"%Y%m%d%H%M%S\"), \".xlsx\")\r\n  #   },\r\n  #   content = function(file) {\r\n  #     req(rv$def, rv$data)\r\n  #     wb <- openxlsx::createWorkbook()\r\n  #     \r\n  #     # ---- 1) original-like sheets ----\r\n  #     openxlsx::addWorksheet(wb, \"Definition\")\r\n  #     \r\n  #     export_df <- rv$def\r\n  #     idx_cont <- export_df$Type == \"continuous\"\r\n  #     \r\n  #     # 1) まず“文字列”で全部書く（ここでcategoricalは正しく入る）\r\n  #     out_df_chr <- data.frame(\r\n  #       Parameter = as.character(export_df$Parameter),\r\n  #       Type      = as.character(export_df$Type),\r\n  #       Min       = as.character(export_df$Min_raw),\r\n  #       Standard  = as.character(export_df$Standard_raw),\r\n  #       Max       = as.character(export_df$Max_raw),\r\n  #       Interval  = as.character(export_df$Interval),\r\n  #       Purpose   = as.character(export_df$Purpose),\r\n  #       stringsAsFactors = FALSE\r\n  #     )\r\n  #     \r\n  #     openxlsx::writeData(wb, \"Definition\", out_df_chr, colNames = TRUE)\r\n  #     \r\n  #     # 2) continuous 行だけ、数値で上書き（セル型が numeric になる）\r\n  #     cont_rows <- which(idx_cont) + 1  # +1 はヘッダ行分\r\n  #     if (length(cont_rows) > 0) {\r\n  #       # numeric化（連続値だけ）\r\n  #       min_num <- suppressWarnings(as.numeric(export_df$Min_raw[idx_cont]))\r\n  #       std_num <- suppressWarnings(as.numeric(export_df$Standard_raw[idx_cont]))\r\n  #       max_num <- suppressWarnings(as.numeric(export_df$Max_raw[idx_cont]))\r\n  #       \r\n  #       # 行ごとに上書き（確実）\r\n  #       for (k in seq_along(cont_rows)) {\r\n  #         r <- cont_rows[k]\r\n  #         openxlsx::writeData(wb, \"Definition\", x = min_num[k], startCol = 3, startRow = r, colNames = FALSE)\r\n  #         openxlsx::writeData(wb, \"Definition\", x = std_num[k], startCol = 4, startRow = r, colNames = FALSE)\r\n  #         openxlsx::writeData(wb, \"Definition\", x = max_num[k], startCol = 5, startRow = r, colNames = FALSE)\r\n  #       }\r\n  #     }\r\n  #     \r\n  #     \r\n  #     \r\n  #     \r\n  #     openxlsx::addWorksheet(wb, \"Data\")\r\n  #     openxlsx::writeData(wb, \"Data\", rv$data)\r\n  #     \r\n  #     # ---- 3) Fit summary (tabular) ----\r\n  #     # ---- 3) Fit summary (tabular) ----\r\n  #     openxlsx::addWorksheet(wb, \"Fit\")\r\n  #     \r\n  #     if (!is.null(rv$fit) && !is.null(rv$fit$fit)) {\r\n  #       f <- rv$fit$fit\r\n  #       # ---- y_hat（長いので別シート）----\r\n  #       openxlsx::addWorksheet(wb, \"Prediction\")\r\n  #       yorg_vec <- as.numeric(rv$fit$yorg)\r\n  #       ypred_vec <- as.numeric(rv$fit$y_pred)\r\n  #       yhat_df <- data.frame(\r\n  #         id = rv$data$id,\r\n  #         y = yorg_vec,\r\n  #         y_pred = ypred_vec,\r\n  #         stringsAsFactors = FALSE\r\n  #       )\r\n  #       openxlsx::writeData(wb, \"Prediction\", yhat_df)\r\n  #       \r\n  #       # ---- 基本のスカラー値だけを key-value で保存（ここは絶対に落ちない）----\r\n  #       fit_df <- data.frame(\r\n  #         item  = c(\"sf2\", \"ell\", \"sigma2\", \"sigma_cat2\", \"rmse_total\", \"eps_var_hat\"),\r\n  #         value = c(f$sf2, f$ell, f$sigma2, f$sigma_cat2, f$rmse_total, f$eps_var_hat),\r\n  #         stringsAsFactors = FALSE\r\n  #       )\r\n  #       openxlsx::writeData(wb, \"Fit\", fit_df)\r\n  #       \r\n  #       # ---- beta（表形式）----\r\n  #       openxlsx::addWorksheet(wb, \"Fit_beta\")\r\n  #       p <- length(f$mu_beta)\r\n  #       beta_df <- data.frame(\r\n  #         beta = paste0(\"beta[\", seq_len(p), \"]\"),\r\n  #         mu   = as.numeric(f$mu_beta),\r\n  #         sd   = sqrt(pmax(diag(f$Sigma_beta), 0)),\r\n  #         stringsAsFactors = FALSE\r\n  #       )\r\n  #       openxlsx::writeData(wb, \"Fit_beta\", beta_df)\r\n  #       \r\n  #     } else {\r\n  #       openxlsx::writeData(wb, \"Fit\", data.frame(msg = \"No fitted model yet.\"))\r\n  #     }\r\n  #     \r\n  #     # ---- 4) Analyze ----\r\n  #     openxlsx::addWorksheet(wb, \"Analyze\")\r\n  #     if (!is.null(rv$plot_df)) {\r\n  #       openxlsx::writeData(wb, \"Analyze\", data.frame(msg=\"test\"))\r\n  #     } else {\r\n  #       openxlsx::writeData(wb, \"Analyze\", data.frame(msg=\"No analysis yet.\"))\r\n  #     }\r\n  #     \r\n  #     # ---- 2) candidates ----\r\n  #     openxlsx::addWorksheet(wb, \"Candidates\")\r\n  #     if (!is.null(rv$cand)) {\r\n  #       openxlsx::writeData(wb, \"Candidates\", rv$cand)\r\n  #     } else {\r\n  #       openxlsx::writeData(wb, \"Candidates\", data.frame(msg=\"No candidates yet.\"))\r\n  #     }\r\n  #     \r\n  #     # ---- save ----\r\n  #     openxlsx::saveWorkbook(wb, file = file, overwrite = TRUE)\r\n  #   }\r\n  # )\r\n  \r\n  \r\n  # output$btn_download_template <- downloadHandler(\r\n  #   filename = function() {\r\n  #     paste0(\"template_\", format(Sys.time(), \"%Y%m%d%H%M%S\"), \".xlsx\")\r\n  #   },\r\n  #   content = function(file) {\r\n  #     wb <- openxlsx::createWorkbook()\r\n  #     \r\n  #     # ---- Definition sheet (template) ----\r\n  #     openxlsx::addWorksheet(wb, \"Definition\")\r\n  #     \r\n  #     def_template <- data.frame(\r\n  #       Parameter = c(\"X1\", \"X2\", \"X3\", \"Y1\"),\r\n  #       Type      = c(\"continuous\", \"continuous\", \"categorical\", \"output\"),\r\n  #       Min       = c(\"-1\", \"0\", \"A\", \"\"),          # categoricalは文字でOK\r\n  #       Standard  = c(\"0\", \"5\", \"B\", \"\"),\r\n  #       Max       = c(\"1\", \"10\", \"C\", \"\"),\r\n  #       Interval  = c(\"0.1\", \"1\", \"\", \"\"),          # categoricalは空でOK\r\n  #       Purpose   = c(\"\", \"\", \"\", \">2\"),            # 例: >2, <1, >=0 など\r\n  #       stringsAsFactors = FALSE\r\n  #     )\r\n  #     \r\n  #     openxlsx::writeData(wb, \"Definition\", def_template)\r\n  #     \r\n  #     # ちょい見やすく\r\n  #     openxlsx::freezePane(wb, \"Definition\", firstRow = TRUE)\r\n  #     openxlsx::setColWidths(wb, \"Definition\", cols = 1:ncol(def_template), widths = \"auto\")\r\n  #     \r\n  #     # ---- Data sheet (template) ----\r\n  #     openxlsx::addWorksheet(wb, \"Data\")\r\n  #     \r\n  #     # 例として列だけ用意（行は空でもOK）\r\n  #     # ここは「id + X* + Y*」の形にするのがポイント\r\n  #     data_template <- data.frame(\r\n  #       id = character(0),\r\n  #       X1 = numeric(0),\r\n  #       X2 = numeric(0),\r\n  #       X3 = character(0),   # categoricalは文字\r\n  #       Y1 = numeric(0),\r\n  #       stringsAsFactors = FALSE\r\n  #     )\r\n  #     \r\n  #     openxlsx::writeData(wb, \"Data\", data_template)\r\n  #     openxlsx::freezePane(wb, \"Data\", firstRow = TRUE)\r\n  #     openxlsx::setColWidths(wb, \"Data\", cols = 1:ncol(data_template), widths = \"auto\")\r\n  #     \r\n  #     # 保存\r\n  #     openxlsx::saveWorkbook(wb, file = file, overwrite = TRUE)\r\n  #   }\r\n  # )\r\n  \r\n  \r\n})\r\n","type":"text"},{"name":"ui.R","content":"library(shiny)\r\n#library(DT)\r\n#library(bslib)\r\n\r\nshinyUI(\r\n  fluidPage(\r\n    # theme = bs_theme(\r\n    #   version = 5,\r\n    #   bootswatch = \"darkly\"\r\n    # ),\r\n    \r\n    tags$head(\r\n      tags$style(HTML(\"\r\n    :root{\r\n      --bg: #0b0f16;\r\n      --panel: #0f1623;\r\n      --card: #111b2b;\r\n      --text: #e9eef7;\r\n      --muted: rgba(233,238,247,0.70);\r\n      --border: rgba(255,255,255,0.10);\r\n      --accent: #4ea1ff;\r\n      --accent2: #7dd3fc;\r\n      --dangerBg: #3b1218;\r\n      --dangerBorder: #a33;\r\n      --dangerText: #ffd6d6;\r\n    }\r\n\r\n    body{\r\n      background: var(--bg);\r\n      color: var(--text);\r\n      overflow-x: hidden;\r\n      font-family: system-ui, -apple-system, Segoe UI, Roboto, Helvetica, Arial, \\\"Noto Sans\\\", \\\"Liberation Sans\\\", sans-serif;\r\n      line-height: 1.45;\r\n      font-size: 14px;\r\n    }\r\n\r\n    a{ color: var(--accent2); }\r\n    a:hover{ color: var(--accent); text-decoration: none; }\r\n\r\n    .app-wrap{\r\n      display:flex;\r\n      gap:14px;\r\n      padding:14px;\r\n      width:100%;\r\n      box-sizing:border-box;\r\n    }\r\n\r\n    .side{\r\n      width:260px; min-width:260px; max-width:260px;\r\n      display:flex; flex-direction:column; gap:12px;\r\n    }\r\n\r\n    .main{\r\n      flex:1;\r\n      width:100%;\r\n      background: var(--panel);\r\n      border:1px solid var(--border);\r\n      border-radius:12px;\r\n      padding:12px;\r\n      box-shadow: 0 10px 30px rgba(0,0,0,0.35);\r\n      box-sizing:border-box;\r\n    }\r\n\r\n    /* cards */\r\n    .cardx{\r\n      background: var(--card);\r\n      border: 1px solid var(--border);\r\n      border-radius: 12px;\r\n      padding: 12px;\r\n      box-shadow: 0 6px 16px rgba(0,0,0,0.25);\r\n    }\r\n\r\n    .box-title{\r\n      font-weight: 700;\r\n      font-size: 13px;\r\n      letter-spacing: 0.02em;\r\n      color: var(--text);\r\n      margin-bottom: 10px;\r\n      opacity: 0.95;\r\n    }\r\n\r\n    .note{\r\n      margin-top: 8px;\r\n      font-size: 12px;\r\n      color: var(--muted);\r\n    }\r\n\r\n    /* Bootstrap row margin kill */\r\n    .row{ margin-left:0 !important; margin-right:0 !important; }\r\n\r\n    /* inputs */\r\n    .form-control, .selectize-input, .selectize-dropdown, .input-group-addon{\r\n      background: rgba(255,255,255,0.06) !important;\r\n      color: var(--text) !important;\r\n      border: 1px solid var(--border) !important;\r\n      border-radius: 10px !important;\r\n      box-shadow: none !important;\r\n    }\r\n    .form-control::placeholder{ color: rgba(233,238,247,0.45); }\r\n    .control-label{ color: var(--muted); font-weight: 600; font-size: 12px; }\r\n    .selectize-dropdown .option{ color: #0b0f16; } /* dropdownは明背景になりがちなので文字を暗く */\r\n    .selectize-dropdown{ border-radius: 10px !important; }\r\n\r\n    /* buttons */\r\n    .btn{\r\n      border-radius: 10px;\r\n      border: 1px solid var(--border);\r\n      background: rgba(255,255,255,0.06);\r\n      color: var(--text);\r\n      font-weight: 700;\r\n    }\r\n    .btn:hover{ filter: brightness(1.08); color: var(--text); }\r\n    .btn-primary{\r\n      background: linear-gradient(180deg, rgba(78,161,255,0.95), rgba(78,161,255,0.70));\r\n      border-color: rgba(78,161,255,0.40);\r\n    }\r\n    .btn-wide{ width:100%; }\r\n\r\n    /* tabs (tabsetPanel) */\r\n    .nav-tabs{\r\n      border-bottom: 1px solid var(--border);\r\n    }\r\n    .nav-tabs > li > a{\r\n      background: transparent !important;\r\n      border: 1px solid transparent !important;\r\n      color: var(--muted) !important;\r\n      font-weight: 700;\r\n      border-radius: 10px 10px 0 0;\r\n      margin-right: 6px;\r\n    }\r\n    .nav-tabs > li.active > a,\r\n    .nav-tabs > li.active > a:focus,\r\n    .nav-tabs > li.active > a:hover{\r\n      background: rgba(255,255,255,0.06) !important;\r\n      border-color: var(--border) !important;\r\n      color: var(--text) !important;\r\n    }\r\n    .tab-content{\r\n      padding-top: 10px;\r\n    }\r\n\r\n    /* tables (renderTable/tableOutput) */\r\n    .table{\r\n      color: var(--text);\r\n      margin-bottom: 0;\r\n    }\r\n    .table > thead > tr > th{\r\n      border-bottom: 1px solid var(--border);\r\n      color: var(--text);\r\n      font-size: 12px;\r\n      opacity: 0.95;\r\n    }\r\n    .table > tbody > tr > td{\r\n      border-top: 1px solid rgba(255,255,255,0.06);\r\n      vertical-align: middle;\r\n      font-size: 12px;\r\n      color: rgba(233,238,247,0.92);\r\n    }\r\n    .table > tbody > tr:hover{\r\n      background: rgba(255,255,255,0.04);\r\n    }\r\n\r\n    /* verbatim text */\r\n    pre, code{\r\n      color: rgba(233,238,247,0.92);\r\n      background: rgba(0,0,0,0.25);\r\n      border: 1px solid rgba(255,255,255,0.08);\r\n      border-radius: 10px;\r\n      padding: 10px;\r\n    }\r\n\r\n    /* Plot container */\r\n    .fixed-plot{ height: 460px; }\r\n\r\n    /* your error UI uses inline styles already, but keep vars */\r\n    .errorbox{\r\n      background: var(--dangerBg);\r\n      border: 1px solid var(--dangerBorder);\r\n      color: var(--dangerText);\r\n    }\r\n    \r\n    .table {\r\n      color: #e9eef7 !important;\r\n      background: #0f1623;\r\n    }\r\n    \r\n    .table > thead > tr > th {\r\n      background: #162133;\r\n      color: #ffffff !important;\r\n      font-weight: 700;\r\n    }\r\n    \r\n    .table > tbody > tr > td {\r\n      color: #e9eef7 !important;\r\n      border-top: 1px solid rgba(255,255,255,0.08);\r\n    }\r\n    \r\n    .table > tbody > tr:hover {\r\n      background: rgba(255,255,255,0.06);\r\n    }\r\n    \r\n        /* selectInput dropdown fix */\r\n    .selectize-dropdown {\r\n      background: #ffffff !important;\r\n      color: #000000 !important;\r\n      border-radius: 10px !important;\r\n    }\r\n    \r\n    .selectize-dropdown .option {\r\n      background: #ffffff !important;\r\n      color: #000000 !important;\r\n    }\r\n    \r\n    .selectize-dropdown .option.active {\r\n      background: #4ea1ff !important;\r\n      color: #ffffff !important;\r\n    }\r\n    \r\n    .selectize-input {\r\n      background: rgba(255,255,255,0.06) !important;\r\n      color: #e9eef7 !important;\r\n    }\"))\r\n  ),\r\n    \r\n    div(class = \"app-wrap\",\r\n        # ----- Sidebar -----\r\n        div(class = \"side\",\r\n            div(class = \"cardx\",\r\n                div(class = \"box-title\", \"File Upload\"),\r\n                fileInput(\"file_xlsx\", label = NULL, accept = c(\".xlsx\", \".xls\")),\r\n                uiOutput(\"ui_sheet\"),       # server側でNULL返すなら何も出ない\r\n                uiOutput(\"ui_col_select\"),  # server側でNULL返すなら何も出ない\r\n                uiOutput(\"ui_error\"), # error message\r\n                actionButton(\"btn_fit\", \"Fit model\", class = \"btn-wide btn-primary\")\r\n            ),\r\n            \r\n            \r\n            div(class = \"cardx\",\r\n                div(class = \"box-title\", \"Input / Output info\"),\r\n                uiOutput(\"ui_info\")\r\n            ),\r\n            #downloadButton(\"btn_download_template\", \"Download Excel template\"),\r\n            tags$a(\r\n              href = \"https://github.com/long-rh/AutoXP3/raw/c4f45f3afd50a2f1d38c29fcaa5883910b758caa/template.xlsx\",\r\n              download = \"template.xlsx\",\r\n              \"Download Excel template\"\r\n            )\r\n            #downloadButton(\"btn_save\", \"Save Report\", class = \"btn-wide save-btn\")\r\n        ),\r\n        \r\n        # ----- Main -----\r\n        div(class = \"main\",\r\n            tabsetPanel(\r\n              id = \"tabs\", type = \"tabs\",\r\n              \r\n              tabPanel(\"1. Data\",\r\n                       fluidRow(\r\n                         column(12,\r\n                                div(class = \"cardx\",\r\n                                    div(class = \"box-title\", \"Uploaded Data (Data sheet)\"),\r\n                                    tableOutput(\"tbl_uploaded_data\")\r\n                                    #DTOutput(\"tbl_uploaded_data\")\r\n                                )\r\n                         )\r\n                       ),\r\n                       br(),\r\n                       fluidRow(\r\n                         column(12,\r\n                                div(class = \"cardx\",\r\n                                    div(class = \"box-title\", \"Definition sheet\"),\r\n                                    tableOutput(\"tbl_definition\")\r\n                                    #DTOutput(\"tbl_definition\")\r\n                                )\r\n                         )\r\n                       )\r\n              ),\r\n              tabPanel(\"2. Model\",\r\n                       # 上段：操作 + グラフ\r\n                       fluidRow(\r\n                         column(4,\r\n                                fluidRow(\r\n                                  column(6, numericInput(\"hp2\", \"RBF length\", value = 0.4, min = 1e-6, step = 0.1)),\r\n                                  column(6, numericInput(\"hp3\", \"RBF noize\", value = 0.05, min = 1e-6, step = 0.01))\r\n                                ),\r\n                                # fluidRow(\r\n                                #   column(6, numericInput(\"hp1\", \"sf2\", value = 1, min = 1e-6, step = 0.1))\r\n                                # ),\r\n                                # fluidRow(\r\n                                #   column(6, numericInput(\"hp_sigma0\", \"sigma0\", value = 100, min = 1e-6, step = 0.1))\r\n                                # ),\r\n                                # fluidRow(\r\n                                #   column(6, numericInput(\"hp_cat\", \"sigma_cat2\", value = 0.5, min = 0, step = 0.1))\r\n                                # ),\r\n                                fluidRow(\r\n                                  column(6, actionButton(\"btn_refit\", \"Refit\"))\r\n                                )\r\n                         ),\r\n                         column(8,\r\n                                div(class = \"cardx fixed-plot\",\r\n                                    plotOutput(\"plot_pred_vs_obs\", height = \"100%\")\r\n                                )\r\n                         )\r\n                       ),\r\n                       \r\n                       br(),\r\n                       \r\n                       # fitting info\r\n                       fluidRow(\r\n                         column(12,\r\n                                div(class = \"cardx\",\r\n                                    div(class = \"box-title\", \"Fitting result information\"),\r\n                                    verbatimTextOutput(\"fit_info\")\r\n                                )\r\n                         )\r\n                       )\r\n              ),\r\n              \r\n              tabPanel(\"3. Analyze\",\r\n                       fluidRow(\r\n                         column(4,\r\n                                div(class = \"cardx\",\r\n                                    uiOutput(\"ui_x12_select\"),\r\n                                    div(class = \"note\", \"Other X are fixed at Standard in Definition (or Min if missing).\")\r\n                                )\r\n                         ),\r\n                         column(8,\r\n                                div(class = \"cardx fixed-plot\",\r\n                                    plotOutput(\"plot_1d\", height = \"100%\")\r\n                                )\r\n                         )\r\n                       )\r\n              ),\r\n              \r\n              tabPanel(\"4. Optimize\",\r\n                       fluidRow(\r\n                         column(12,\r\n                                div(class = \"cardx\",\r\n                                    #actionButton(\"btn_suggest\", \"Suggest next experiments\", class = \"btn-wide btn-primary\")\r\n                                    uiOutput(\"ui_btn_suggest\")\r\n                                )\r\n                         ),\r\n                         br(),\r\n                         column(12,\r\n                                div(class = \"cardx\",\r\n                                    #DTOutput(\"tbl_candidates\")\r\n                                    tableOutput(\"tbl_candidates\")\r\n                                )\r\n                         )\r\n                       )\r\n              )\r\n            )\r\n        )\r\n    )\r\n  )\r\n)\r\n","type":"text"},{"name":"R/categorical-kernel.R","content":"# ---- Additive delta kernels for any number of categorical columns ----\r\n# df: data.frame whose columns are categorical (factor/character)\r\n# Returns:\r\n#  - Kc_total: sum of delta kernels across all categorical columns\r\n#  - Kc_list : per-column delta kernel matrices\r\n#  - sigmas2 : the sigma^2 used per column (named)\r\n#\r\n# Delta kernel for one categorical vector:\r\n#   K[i,j] = sigma2 if cat_i == cat_j else 0\r\n\r\ndelta_kernel <- function(cat1, cat2, sigma2 = 0.05) {\r\n  c1 <- as.character(as.factor(cat1))\r\n  c2 <- as.character(as.factor(cat2))\r\n  sigma2 * (outer(c1, c2, FUN = \"==\") * 1.0)\r\n}\r\n\r\nadditive_delta_kernels <- function(df, sigma2 = 0.05, sigma2_by_col = NULL) {\r\n  if (!is.data.frame(df)) stop(\"df must be a data.frame\")\r\n  \r\n  n <- nrow(df)\r\n  if (n == 0) stop(\"df has 0 rows\")\r\n  \r\n  p <- ncol(df)\r\n  if (p == 0) stop(\"df has 0 columns (no categorical variables).\")\r\n  \r\n  # identify categorical columns automatically\r\n  is_cat <- vapply(df, function(x) is.factor(x) || is.character(x), logical(1))\r\n  if (!any(is_cat)) stop(\"No categorical columns found (factor/character).\")\r\n  \r\n  cat_cols <- names(df)[is_cat]\r\n  \r\n  # set sigma^2 per column\r\n  if (is.null(sigma2_by_col)) {\r\n    sigmas2 <- setNames(rep(sigma2, length(cat_cols)), cat_cols)\r\n  } else {\r\n    if (is.null(names(sigma2_by_col))) stop(\"sigma2_by_col must be a named numeric vector.\")\r\n    missing <- setdiff(cat_cols, names(sigma2_by_col))\r\n    if (length(missing) > 0) stop(\"sigma2_by_col is missing: \", paste(missing, collapse = \", \"))\r\n    sigmas2 <- sigma2_by_col[cat_cols]\r\n  }\r\n  \r\n  # build per-column delta kernels and sum them\r\n  Kc_list <- lapply(cat_cols, function(col) {\r\n    delta_kernel(df[[col]], df[[col]], sigma2 = sigmas2[[col]])\r\n  })\r\n  names(Kc_list) <- cat_cols\r\n  \r\n  Kc_total <- Reduce(`+`, Kc_list)\r\n  # numeric safety\r\n  Kc_total <- (Kc_total + t(Kc_total)) / 2\r\n  \r\n  list(\r\n    n = n,\r\n    n_cat_vars = length(cat_cols),\r\n    cat_vars = cat_cols,\r\n    sigmas2 = sigmas2,\r\n    Kc_list = Kc_list,\r\n    Kc_total = Kc_total\r\n  )\r\n}\r\n\r\n# ---- Example (your df) ----\r\n# df <- data.frame(\r\n#   C1 = factor(c(\"A\", \"B\")),\r\n#   C2 = factor(c(\"a\", \"b\"))\r\n# )\r\n# \r\n# res <- additive_delta_kernels(df, sigma2 = c(0.05, 0.03))#categoryごとにσを指定可能\r\n# \r\n# res$n_cat_vars      # number of categorical variables detected\r\n# res$cat_vars        # their names\r\n# res$Kc_list$C1       # delta kernel for C1\r\n# res$Kc_list$C2       # delta kernel for C2\r\n# res$Kc_total         # additive delta kernel sum: Kc1 + Kc2\r\n\r\n","type":"text"},{"name":"R/kernel.R","content":"# ---------- Linear algebra helper: solve V x = b via Cholesky ----------\r\nchol_solve <- function(L, b) {\r\n  # Given V = L %*% t(L) with L lower-triangular (from chol(..., pivot=FALSE)),\r\n  # solve V x = b\r\n  y <- forwardsolve(L, b, upper.tri = FALSE, transpose = FALSE)\r\n  x <- backsolve(t(L), y, upper.tri = TRUE, transpose = FALSE)\r\n  x\r\n}\r\n\r\n# ---------- For each matrix component ---------------------------------------------\r\nkernel <- function(xi, xj, type = c(\"rbf\", \"linear\", \"quad\", \"rbf_linear\"),\r\n                   theta1 = 1, theta2 = 0.4) {\r\n  type <- match.arg(type)\r\n  switch(type,\r\n         rbf = {\r\n           d2 <- sum((xi - xj)^2)\r\n           return(theta1 * exp(-0.5*d2 / theta2))\r\n         },\r\n         \r\n         linear = {\r\n           return(sum(xi*xj) + 1)\r\n         },\r\n         \r\n         quad = {\r\n           return((sum(xi*xj) + 1)^2)\r\n         },\r\n         rbf_linear = {\r\n           d2 <- sum((xi - xj)^2)\r\n           return(theta1 * exp(-0.5*d2 / theta2) + sum(xi*xj) + 1)\r\n         }\r\n  )\r\n}\r\n\r\n\r\n# ---------- Matrix build ---------------------------------------------\r\nkernel_matrix <- function(X1, X2 = X1,\r\n                          type = \"rbf\",\r\n                          theta1 = 1,\r\n                          theta2 = 1,\r\n                          noise = 0,\r\n                          jitter = 1e-5) {\r\n  X1 <- as.matrix(X1)\r\n  X2 <- as.matrix(X2)\r\n  N1 <- nrow(X1)\r\n  N2 <- nrow(X2)\r\n  K <- matrix(0, nrow = N1, ncol = N2)\r\n  \r\n  for (i in 1:N1) {\r\n    xi <- X1[i, , drop = FALSE]\r\n    for (j in 1:N2) {\r\n      xj <- X2[j, , drop = FALSE]\r\n      K[i, j] <- kernel(xi, xj,\r\n                        type = type,\r\n                        theta1 = theta1,\r\n                        theta2 = theta2)\r\n    }\r\n  }\r\n  # noise for only diagonal component\r\n  if (noise != 0 && identical(X1, X2)) {\r\n    K <- K + noise * diag(N1)\r\n  }\r\n  return(K)\r\n}\r\n\r\n#GPに算\r\nGP_pred <- function(X_train, Y_train, X_pred, \r\n                    theta1 = 1, theta2 = 1,\r\n                    theta3 = 0, #noise\r\n                    type = c(\"rbf\", \"linear\", \"quad\", \"rbf_linear\")\r\n                    ){\r\n                    #check input\r\n                    X_train <- as.matrix(X_train)\r\n                    Y_train <- as.matrix(Y_train)\r\n                    X_pred <- as.matrix(X_pred)\r\n                    N <- nrow(X_train)\r\n                    M <- nrow(X_pred)\r\n                    if (N != length(Y_train)){\r\n                      stop(\"length(x_train) must equal length(y_train)\")\r\n                    }\r\n                    # learning K(N×N) with noise\r\n                    K <- kernel_matrix(X_train, X_train,\r\n                                       type = type,\r\n                                       theta1 = theta1, theta2 = theta2,\r\n                                       noise = theta3)\r\n                    \r\n                    # prediction k(N×M): without noise\r\n                    k <- kernel_matrix(X_train, X_pred,\r\n                                       type = type,\r\n                                       theta1 = theta1, theta2 = theta2)\r\n                    \r\n                    # prediction s(M×M)\r\n                    s <- kernel_matrix(X_pred, X_pred,\r\n                                       type = type,\r\n                                       theta1 = theta1, theta2 = theta2)\r\n                    \r\n                    # Cholesky: V = L L^T\r\n                    L <- chol(K)  # upper-tri by default in R: chol(V) returns U s.t. t(U)U = V\r\n                    # We'll convert to lower-tri for forwardsolve/backsolve style:\r\n                    # If U is upper, then V = t(U)U => let L = t(U)\r\n                    L <- t(L)\r\n                    \r\n                    yy <- chol_solve(L, Y_train)#K*yy = y_train, solve yy\r\n                    v  <- chol_solve(L, k)#Kv=k, solve v\r\n                    mu <- t(k)%*%yy#mean\r\n                    var_f <- s - t(k) %*% v #fuction variance var_f(M×M)\r\n                    if (abs(theta3) > .Machine$double.eps^0.5) {\r\n                      var_y <- var_f + theta3 * diag(M) #observation variance var_y\r\n                      return(list(mu = mu, var_f = var_f, var_y = var_y))\r\n                    } else {\r\n                      return(list(mu = mu, var_f = var_f))\r\n                    }\r\n}","type":"text"},{"name":"R/optimize_ucb.R","content":"# ============================================================\r\n# UCB Optimization utilities\r\n# ============================================================\r\n\r\n# ============================================================\r\n# Threshold-aware acquisition\r\n# purpose: \">2\", \">=2\", \"<5\", \"<=5\"\r\n# score: (mean shift from threshold) + kappa * sd\r\n#   - for \">\" : (mu - thr) + kappa*sd\r\n#   - for \"<\" : (thr - mu) + kappa*sd\r\n# Notes:\r\n# - This keeps the same \"UCB style\" while respecting the threshold.\r\n# ============================================================\r\nucb_score <- function(mu, sd, purpose, kappa = 2.0, parse_fun = parse_purpose) {\r\n  \r\n  pp <- parse_fun(purpose)\r\n  \r\n  mu <- as.numeric(mu)\r\n  sd <- as.numeric(sd)\r\n  sd <- pmax(sd, 1e-12)  # avoid zero\r\n  \r\n  # default: maximize mu\r\n  if (pp$type != \"bound\" || !is.finite(pp$value)) {\r\n    return(mu + kappa * sd)\r\n  }\r\n  \r\n  thr <- pp$value\r\n  \r\n  if (pp$op %in% c(\">\", \">=\")) {\r\n    # maximize \"margin above threshold\" with uncertainty bonus\r\n    return((mu - thr) + kappa * sd)\r\n  }\r\n  \r\n  if (pp$op %in% c(\"<\", \"<=\")) {\r\n    # minimize mu => maximize \"margin below threshold\"\r\n    return((thr - mu) + kappa * sd)\r\n  }\r\n  \r\n  # fallback\r\n  mu + kappa * sd\r\n}\r\n\r\n\r\n\r\nmake_boundary_points <- function(Xnames, def2, Xtrain = NULL) {\r\n  \r\n  d <- length(Xnames)\r\n  \r\n  base <- numeric(d)\r\n  \r\n  for (k in seq_len(d)) {\r\n    nm <- Xnames[k]\r\n    row <- def2[def2$Parameter == nm, , drop = FALSE]\r\n    \r\n    v <- row$standard[1]\r\n    \r\n    if (!is.finite(v)) {\r\n      if (!is.null(Xtrain)) {\r\n        v <- median(Xtrain[, k], na.rm = TRUE)\r\n      } else {\r\n        v <- 0\r\n      }\r\n    }\r\n    \r\n    base[k] <- v\r\n  }\r\n  \r\n  mins <- def2$min[match(Xnames, def2$Parameter)]\r\n  maxs <- def2$max[match(Xnames, def2$Parameter)]\r\n  \r\n  pts <- list()\r\n  \r\n  for (k in seq_len(d)) {\r\n    p1 <- base; p1[k] <- mins[k]\r\n    p2 <- base; p2[k] <- maxs[k]\r\n    pts[[length(pts)+1]] <- p1\r\n    pts[[length(pts)+1]] <- p2\r\n  }\r\n  \r\n  if (d <= 6) {\r\n    corners <- expand.grid(rep(list(c(0,1)), d))\r\n    corners <- as.matrix(corners)\r\n    \r\n    for (i in seq_len(nrow(corners))) {\r\n      pt <- ifelse(corners[i,] == 0, mins, maxs)\r\n      pts[[length(pts)+1]] <- pt\r\n    }\r\n  }\r\n  \r\n  M <- do.call(rbind, pts)\r\n  colnames(M) <- Xnames\r\n  \r\n  unique(as.data.frame(M))\r\n}","type":"text"},{"name":"R/semiparam_bayes.R","content":"# ============================================================\r\n# Semi-parametric Bayesian regression: y = X beta + u + eps\r\n# beta ~ N(mu0, Sigma0), u ~ N(0, K), eps ~ N(0, sigma2 I)\r\n# Hyperparameters (kernel + sigma2) are treated as fixed.\r\n# ============================================================\r\n\r\n# ---------- Fit function ---------- #Step1 posterior beta|y\r\nfit_semiparam_bayes <- function(y, X, Z, Z_cat=NULL, sigma_cat2=10,\r\n                                mu0 = NULL,#beta事前\r\n                                Sigma0 = 100,#beta事前\r\n                                sigma2 = 1.0,#ε分散\r\n                                ell = 1.0,#rbf距離parameter\r\n                                sf2 = 1.0,#rbf係数parameter\r\n                                jitter = 1e-8) {\r\n  \r\n  y <- as.numeric(y)\r\n  X <- as.matrix(X)\r\n  Z <- as.matrix(Z)\r\n  n <- length(y)\r\n  p <- ncol(X)\r\n  \r\n  if (is.null(mu0)) mu0 <- rep(0, p)\r\n  if (is.null(Sigma0)) Sigma0 <- diag(1e4, p)  # weak prior by default (assumes standardized X)\r\n  mu0 <- as.numeric(mu0)\r\n  Sigma0 <- as.matrix(Sigma0)\r\n  \r\n  #categorical factor\r\n  K_cat <- NULL\r\n  sigmas2_cat <- NULL\r\n  \r\n  if (!is.null(Z_cat)) {\r\n    if (nrow(Z_cat) != n) stop(\"nrow(Z_cat) must equal length(y).\")\r\n    \r\n    K_cat_raw <- additive_delta_kernels(Z_cat, sigma2 = sigma_cat2)\r\n    \r\n    # additive_delta_kernels() returns a list -> use Kc_total\r\n    if (is.list(K_cat_raw) && !is.null(K_cat_raw$Kc_total)) {\r\n      K_cat <- K_cat_raw$Kc_total\r\n      sigmas2_cat <- K_cat_raw$sigmas2\r\n    } else if (is.matrix(K_cat_raw)) {\r\n      K_cat <- K_cat_raw\r\n      sigmas2_cat <- NULL\r\n    } else {\r\n      stop(\"additive_delta_kernels() returned unsupported type: \", paste(class(K_cat_raw), collapse = \", \"))\r\n    }\r\n    \r\n    K_cat <- as.matrix(K_cat)\r\n    storage.mode(K_cat) <- \"double\"\r\n    if (!all(dim(K_cat) == c(n, n))) stop(\"K_cat must be n x n.\")\r\n  }\r\n  \r\n  \r\n  # Kernel + noise\r\n  K <- kernel_matrix(Z, Z, type=\"rbf\", theta2 = ell, theta1 = sf2)\r\n  V <- K + sigma2 * diag(n)\r\n  # Categorical kernel\r\n  if (!is.null(K_cat)) V <- V + K_cat\r\n  \r\n  # Add jitter for numerical stability\r\n  V <- V + jitter * diag(n)\r\n  \r\n  # Cholesky: V = L L^T\r\n  L <- chol(V)  # upper-tri by default in R: chol(V) returns U s.t. t(U)U = V\r\n  # We'll convert to lower-tri for forwardsolve/backsolve style:\r\n  # If U is upper, then V = t(U)U => let L = t(U)\r\n  L <- t(L)\r\n  \r\n  # Precompute: V^{-1} X and V^{-1} y\r\n  VinvX <- chol_solve(L, X)         # n x p\r\n  Vinvy <- chol_solve(L, y)         # n\r\n  \r\n  # Posterior for beta: Sigma_beta^{-1} = Sigma0^{-1} + X^T V^{-1} X\r\n  Sigma0_inv <- solve(Sigma0)       # p x p (small p; OK)\r\n  Sigma_beta_inv <- Sigma0_inv + t(X) %*% VinvX\r\n  Sigma_beta <- solve(Sigma_beta_inv)#Q^-1\r\n  \r\n  mu_beta <- Sigma_beta %*% (Sigma0_inv %*% mu0 + t(X) %*% Vinvy)\r\n  mu_beta <- as.numeric(mu_beta)\r\n  \r\n  # Linear residual: y - X mu_beta (= u + eps)\r\n  r_lin <- y - as.numeric(X %*% mu_beta)\r\n  Vinv_r <- chol_solve(L, r_lin)          # V^{-1} r\r\n  u_hat  <- as.numeric(K %*% Vinv_r)      # E[u|y] at training points (continuous part)\r\n  # If categorical kernel was used, add its contribution to u_hat as well\r\n  if (!is.null(K_cat)) {\r\n    u_hat <- u_hat + as.numeric(K_cat %*% Vinv_r)\r\n  }\r\n  y_hat <- as.numeric(X %*% mu_beta + u_hat)\r\n  # Noise-like residual: eps_hat = y - X mu_beta - u_hat = y - y_hat\r\n  eps_hat <- y - y_hat #residual\r\n  eps_var_hat <- if (n > 1) var(eps_hat) else NA_real_ #residual var\r\n  rmse_total <- sqrt(mean((eps_hat)^2)) #rmse\r\n  \r\n  # Store objects needed for prediction\r\n  list(\r\n    y = y, X = X, Z = Z,\r\n    Z_cat  = if (!is.null(Z_cat)) as.data.frame(Z_cat) else NULL,\r\n    mu0 = mu0, Sigma0 = Sigma0,\r\n    sigma2 = sigma2, ell = ell, sf2 = sf2,\r\n    sigma_cat2 = sigma_cat2,\r\n    K = K, V = V, L = L,  # L is lower-tri s.t. V = L L^T\r\n    VinvX = VinvX, Vinvy = Vinvy,\r\n    mu_beta = mu_beta, Sigma_beta = Sigma_beta,\r\n    sigma_cat2s = sigmas2_cat,\r\n    y_hat = y_hat,\r\n    u_hat = u_hat,              # posterior mean of u at training points\r\n    eps_hat = eps_hat,        # y - X mu_beta - u_hat\r\n    eps_var_hat = eps_var_hat,\r\n    rmse_total = rmse_total\r\n  )\r\n}\r\n\r\n# ---------- Predict function (mean/var + variance decomposition) ---------- #Step2 Posterior u|beta, y\r\npredict_semiparam_bayes <- function(fit, Xnew, Znew, Z_cat_new  = NULL,\r\n                                    return_components = TRUE) {\r\n  Xnew <- as.matrix(Xnew)\r\n  Znew <- as.matrix(Znew)\r\n  \r\n  y <- fit$y; X <- fit$X; Z <- fit$Z\r\n  mu_beta <- fit$mu_beta\r\n  Sigma_beta <- fit$Sigma_beta\r\n  sigma2 <- fit$sigma2\r\n  L <- fit$L\r\n  n <- length(y)\r\n  m <- nrow(Xnew)\r\n  \r\n  # K_* (n x m), k_** (m)\r\n  Kstar <- kernel_matrix(Z, Znew, theta1 = fit$sf2, theta2 = fit$ell)     # n x m\r\n  kss <- diag(kernel_matrix(Znew, Znew,  theta1 = fit$sf2, theta2 = fit$ell))  # m\r\n  \r\n  \r\n  # ---------- categorical変数に対して (ここから) --------------------------------------\r\n  Kstar_c <- NULL\r\n  kss_c <- rep(0, m)\r\n  if (!is.null(fit$Z_cat)) {\r\n    if (is.null(Z_cat_new)) stop(\"fit used Z_cat, but Z_cat_new is NULL.\")\r\n    Z_cat_new <- as.data.frame(Z_cat_new)\r\n    \r\n    cols <- names(fit$Z_cat)\r\n    missing <- setdiff(cols, names(Z_cat_new))\r\n    if (length(missing) > 0) stop(\"Z_cat_new missing columns: \", paste(missing, collapse = \", \"))\r\n    \r\n    sig2 <- fit$sigma_cat2s\r\n    if (is.null(sig2)) {\r\n      # fallback: scalar provided\r\n      sig2 <- setNames(rep(as.numeric(fit$sigma_cat2), length(cols)), cols)\r\n    } else {\r\n      sig2 <- sig2[cols]\r\n    }\r\n    \r\n    Kstar_list <- lapply(cols, function(col) {\r\n      delta_kernel(fit$Z_cat[[col]], Z_cat_new[[col]], sigma2 = sig2[[col]])\r\n    })\r\n    Kstar_c <- Reduce(`+`, Kstar_list)\r\n    kss_c <- rep(sum(sig2), m)  # delta(c,c)=1 for each col\r\n  }\r\n  \r\n  if (!is.null(Kstar_c)) {\r\n    Kstar <- Kstar + Kstar_c\r\n    kss <- kss + kss_c\r\n  }\r\n  # ---------- categorical変数に対して (ここまで) --------------------------------------\r\n  \r\n  \r\n  # a = V^{-1} k_*  (n x m)\r\n  a <- chol_solve(L, Kstar)   # n x m\r\n  \r\n  # Mean:\r\n  # E[y*|y] = x*^T mu_beta + k_*^T V^{-1} (y - X mu_beta)\r\n  r <- y - as.numeric(X %*% mu_beta)         # n\r\n  Vinvr <- chol_solve(L, r)                  # n\r\n  mean_gp <- colSums(Kstar * Vinvr)          # m (since k_*^T Vinvr)\r\n  mean_lin <- as.numeric(Xnew %*% mu_beta)   # m\r\n  mean <- mean_lin + mean_gp                 # m\r\n  \r\n  # Variance components:\r\n  # v_gp = k** - k_*^T V^{-1} k_*\r\n  # compute diag(Kstar^T a) efficiently: sum over rows of Kstar * a\r\n  diag_kVinvk <- colSums(Kstar * a)          # m\r\n  v_gp <- pmax(kss - diag_kVinvk, 0)         # numeric guard\r\n  \r\n  # delta = x_* - X^T V^{-1} k_*\r\n  Xt_a <- t(X) %*% a                          # p x m\r\n  delta <- t(Xnew) - Xt_a                     # p x m  (each column is delta for a point)\r\n  \r\n  # v_beta = delta^T Sigma_beta delta  for each m\r\n  # compute per column: t(delta[,i]) %*% Sigma_beta %*% delta[,i]\r\n  Sb_delta <- Sigma_beta %*% delta            # p x m\r\n  v_beta <- colSums(delta * Sb_delta)         # m\r\n  \r\n  # total predictive variance (for observed y*): sigma2 + v_gp + v_beta\r\n  v_total <- sigma2 + v_gp + v_beta\r\n  \r\n  if (!return_components) {\r\n    return(list(mean = mean, var = v_total))\r\n  }\r\n  \r\n  # dominance ratio (ignoring sigma2): beta vs gp\r\n  denom <- v_gp + v_beta\r\n  r_beta <- ifelse(denom > 0, v_beta / denom, NA_real_)\r\n  \r\n  list(\r\n    mean = mean,\r\n    var_total = v_total,\r\n    var_noise = rep(sigma2, m),\r\n    var_gp = v_gp,\r\n    var_beta = v_beta,\r\n    r_beta = r_beta\r\n  )\r\n}\r\n\r\n# ============================================================\r\n# Example usage (replace with your data)\r\n# ============================================================\r\n\r\n\r\n# Suppose:\r\n# y: n-vector\r\n# X: n x p design matrix (include intercept column if you want)\r\n# Z: n x d GP inputs (can be same as X columns if you want, but see note below)\r\n\r\n# ---- Whether applying box-cox transformation\r\n# lambda <- 0.3           # ON\r\n lambda <- NULL          # OFF\r\n\r\n\r\n###############################################################################\r\n# --- Toy example -----------------------------------------------------------\r\n###############################################################################\r\nif (FALSE) {\r\n  set.seed(1)\r\n  n <- 5\r\n  x1 <- seq(-1, 1, length=n)\r\n  x2 <- c(\"A\",\"B\",\"A\",\"B\",\"A\")\r\n  X <- cbind(1, x1)# Only continuous\r\n  Z <- cbind(x1)        # GP on same 2 dims\r\n  \r\n  #categorical\r\n  Z_cat <- data.frame(\"Xc\" = as.character(x2))\r\n  Z_cat\r\n  y_true <- function(x, sd){\r\n    y_true <- 1 + 3*x - 0.5*exp(-2*(x-1)) + 3*rnorm(n, sd = sd)\r\n    #return (abs(y_true)/max(y_true))\r\n    return (y_true/max(y_true))\r\n  }\r\n  set.seed(1)\r\n  y_org <- y_true(x1, sd=2) #+ x2: categorical\r\n  x1\r\n  y_org\r\n  plot(x1, y_org, xlab = \"x\", ylab = \"y\")\r\n  \r\n  y <- fwd_y(y_org, lambda=lambda) #lambdaがNULLでなければbox-cox変換をする\r\n  \r\n  #standardize\r\n  std <- standardize_fit(X, Z, y, standardize_X = TRUE, intercept_col = 1L)\r\n  X_s <- std$X; Z_s <- std$Z; y_s <- std$y\r\n  \r\n  ################################################################################\r\n  # Hyperparameters (fixed)\r\n  ################################################################################\r\n  sigma2 <- 0.05 #εの分散: NULLなら線形回帰の残差から推定, 値を指定してもよい.\r\n  var_beta0 <- 100 #大きな値(e.g.100)→GP支配. 小さな値(ex, 0.1)→線形支配.\r\n  if (is.null(sigma2)){\r\n    fit_lm <- lm(y_s ~ X_s - 1)\r\n    sigma2_lin <- sum(resid(fit_lm)^2) / df.residual(fit_lm)  # unbiased\r\n    sigma2 <- sigma2_lin/10 \r\n  } else{\r\n    sigma2 <- sigma2\r\n  }\r\n  # Prior on beta\r\n  p <- ncol(X) #線形のparameter数\r\n  mu0 <- rep(0, p) #βの事前分布平均\r\n  Sigma0 <- diag(var_beta0, p) #大きな値→GP支配. 小さな値→線形支配.\r\n  \r\n  ell <- 0.4 #rbf kernelの距離paramemter\r\n  sf2 <- 1.0 #rbf kernelの係数\r\n  \r\n  # ------------------ hyperparameterを推定する場合 -----------------------------\r\n  # hyp <- fit_hyperparams_multistart_bounded(\r\n  #   y = y_s, X = X_s, Z = Z_s,\r\n  #   mu0 = mu0, Sigma0 = Sigma0,\r\n  #   ell_grid = c(0.5, 2, 5),\r\n  #   sf2_grid = c(0.1, 1, 10),\r\n  #   sigma2_grid = c(1,5,10),\r\n  #   ell_bounds = c(0.1, 20),\r\n  #   sf2_bounds = c(1e-2, 1e2),\r\n  #   sigma2_bounds = c(1, 10)\r\n  # )\r\n  # hyp$ell; hyp$sf2; hyp$sigma2\r\n  # hyp$opt$value  # minimized negative log marginal likelihood\r\n  #------------------------------------------------------------------------------\r\n  \r\n  \r\n  fit <- fit_semiparam_bayes(y_s, X_s, Z_s, Z_cat = Z_cat,\r\n                             mu0 = mu0, Sigma0 = Sigma0,\r\n                             sigma2 = sigma2, ell = ell, sf2 = sf2)\r\n  \r\n  \r\n  # ------------------- Predict on new points ------------------------------------\r\n  m <- 100\r\n  x1n <- seq(-2, 2, length.out = m)\r\n  Xnew <- cbind(1, x1n) #, exp(-x1n)などの非線形を足してもよい\r\n  Znew <- cbind(x1n)\r\n  Z_cat_new <- data.frame(Xc = rep(\"A\", m))  # 例えば全部Aに固定\r\n  new_s <- standardize_apply(Xnew, Znew, std)\r\n  pred_s <- predict_semiparam_bayes(fit, new_s$X, new_s$Z, Z_cat_new = Z_cat_new,\r\n                                    return_components = TRUE)\r\n  \r\n  \r\n  y_pred <- destandardize_y(pred_s$mean, std) #正規化逆変換\r\n  sd_y<- destandardize_y_sd(sqrt(pred_s$var_total), std) #正規化逆変換\r\n  y_org_pred <- inv_y(y_pred, lambda=lambda)# lambdaがNULLでなければbox-cox逆変換\r\n  y_lo <- y_pred - sd_y\r\n  y_hi <- y_pred + sd_y\r\n  y_org_lo <- inv_y(y_lo, lambda)\r\n  y_org_hi <- inv_y(y_hi, lambda)\r\n  \r\n  #semi-parameteric bayes\r\n  plot(x1,y_org, xlab = \"x\", ylab = \"y\", pch=16,\r\n       xlim=c(min(x1n), max(x1n)), ylim = c(min(y_org_lo), max(y_org_hi)))\r\n  lines(x1n, y_org_pred, col=\"blue\", lty=2)\r\n  lines(x1n, y_org_lo, col=\"blue\")\r\n  lines(x1n, y_org_hi, col=\"blue\")\r\n  lines(x1n, y_true(x1n, 0), lwd=2)\r\n  #lines(x1n, 20*pred$r_beta, col=\"green\")\r\n  #色塗\r\n  polygon(\r\n    c(x1n, rev(x1n)),\r\n    c(y_org_lo, rev(y_org_hi)),\r\n    col=rgb(0, 0, 1, alpha = 0.05),\r\n    border = NA\r\n  )\r\n  \r\n  #linear component\r\n  beta_var <- fit$Sigma_beta\r\n  beta_var\r\n  beta_lo <- fit$mu_beta - diag(beta_var)\r\n  beta_hi <- fit$mu_beta + diag(beta_var)\r\n  # 2) 標準化空間で線形成分を計算\r\n  Xnew_s <- new_s$X\r\n  y_lin_s <- as.numeric(Xnew_s %*% fit$mu_beta)\r\n  # 3) y を元スケールに戻す\r\n  y_lin <- destandardize_y(y_lin_s, std)\r\n  y_lo <- Xnew %*% beta_lo\r\n  y_hi <- Xnew %*% beta_hi\r\n  lines(x1n, y_lin, col=\"red\", lty=2)\r\n  #lines(x1n, y_lo, col=\"red\")\r\n  #lines(x1n, y_hi, col=\"red\")\r\n  \r\n  #普通の最小二乗法\r\n  #res <- lm(y~(x1+x2+1))\r\n  #y_lm <- Xnew %*% res$coefficients\r\n  # lines(x1n, y_lm)\r\n  \r\n  # ----------------------- 通常のGPと比較 -----------------------------------\r\n  #kernel計算\r\n  theta1 <- sf2\r\n  theta2 <- ell^2\r\n  sigma2\r\n  theta3 <- sigma2#noise\r\n  #予測分布の計算 p(y*|x*,X,y)\r\n  res <- GP_pred(X_train=Z_s, Y_train=y_s, X_pred=new_s$Z, type = \"rbf\",\r\n                 theta1 = theta1, theta2 = theta2, theta3 = theta3)\r\n  mu <- destandardize_y(res$mu, std)\r\n  var <- destandardize_y_sd(sqrt(diag(res$var_y)), std)\r\n  \r\n  \r\n  #予測\r\n  lines(x1n, mu, col=\"lightblue\")\r\n  y_min <- mu-sqrt(var)\r\n  y_max <- mu+sqrt(var)\r\n  lines(x1n, y_min, col=\"lightblue\")#y_min\r\n  lines(x1n, y_max, col=\"lightblue\")#y_max\r\n  #色塗\r\n  polygon(\r\n    c(x1n, rev(x1n)),\r\n    c(y_min, rev(y_max)),\r\n    col=rgb(0.68, 0.85, 0.90, alpha = 0.3),\r\n    border = NA\r\n  )\r\n  legend(\"topleft\",\r\n         legend = c(\"Training data\",\r\n                    \"Semi\",\r\n                    \"GP\"),\r\n         pch    = c(16, NA, NA),\r\n         lty    = c(NA, 1, 1),\r\n         lwd    = c(NA, 5, 5),\r\n         col    = c(\"black\",\r\n                    \"blue\",\r\n                    \"lightblue\"),\r\n         pt.cex = 1,\r\n         cex = 0.8,\r\n         bty    = \"n\")\r\n}\r\n","type":"text"},{"name":"R/standardize.R","content":"standardize_fit <- function(X, Z, y,\r\n                            standardize_X = TRUE,\r\n                            intercept_col = 1L) {\r\n  X <- as.matrix(X)\r\n  Z <- as.matrix(Z)\r\n  y <- as.numeric(y)\r\n  \r\n  n <- length(y)\r\n  p <- ncol(X)\r\n  d <- ncol(Z)\r\n  \r\n  # --- y center/scale ---\r\n  y_mean <- mean(y)\r\n  y_sd   <- sd(y)\r\n  if (y_sd == 0) y_sd <- 1\r\n  y_s <- (y - y_mean) / y_sd\r\n  \r\n  # --- Z standardize ---\r\n  Z_mean <- colMeans(Z)\r\n  Z_sd <- apply(Z, 2, sd)\r\n  Z_sd[Z_sd == 0] <- 1\r\n  Z_s <- sweep(sweep(Z, 2, Z_mean, \"-\"), 2, Z_sd, \"/\")\r\n  \r\n  # --- X standardize (optional) ---\r\n  X_s <- X\r\n  X_mean <- rep(0, p)\r\n  X_sd   <- rep(1, p)\r\n  \r\n  if (standardize_X) {\r\n    for (j in seq_len(p)) {\r\n      if (!is.null(intercept_col) && j == intercept_col) {\r\n        # intercept column left unchanged\r\n        X_mean[j] <- 0\r\n        X_sd[j] <- 1\r\n      } else {\r\n        X_mean[j] <- mean(X[, j])\r\n        X_sd[j]   <- sd(X[, j])\r\n        if (X_sd[j] == 0) X_sd[j] <- 1\r\n        X_s[, j] <- (X[, j] - X_mean[j]) / X_sd[j]\r\n      }\r\n    }\r\n  }\r\n  \r\n  list(\r\n    X = X_s, Z = Z_s, y = y_s,\r\n    y_mean = y_mean, y_sd = y_sd,\r\n    Z_mean = Z_mean, Z_sd = Z_sd,\r\n    X_mean = X_mean, X_sd = X_sd,\r\n    standardize_X = standardize_X,\r\n    intercept_col = intercept_col\r\n  )\r\n}\r\n\r\nstandardize_apply <- function(Xnew, Znew, std) {\r\n  Xnew <- as.matrix(Xnew)\r\n  Znew <- as.matrix(Znew)\r\n  \r\n  # apply Z transform\r\n  Z_s <- sweep(sweep(Znew, 2, std$Z_mean, \"-\"), 2, std$Z_sd, \"/\")\r\n  \r\n  # apply X transform (if used)\r\n  X_s <- Xnew\r\n  if (isTRUE(std$standardize_X)) {\r\n    p <- ncol(Xnew)\r\n    for (j in seq_len(p)) {\r\n      if (!is.null(std$intercept_col) && j == std$intercept_col) {\r\n        # intercept unchanged\r\n      } else {\r\n        X_s[, j] <- (Xnew[, j] - std$X_mean[j]) / std$X_sd[j]\r\n      }\r\n    }\r\n  }\r\n  \r\n  list(X = X_s, Z = Z_s)\r\n}\r\n\r\n# For prediction mean back-transform:\r\n# if y was standardized: y = y_mean + y_sd * y_scaled\r\ndestandardize_y <- function(y_scaled, std) {\r\n  std$y_mean + std$y_sd * y_scaled\r\n}\r\n\r\ndestandardize_y_sd <- function(sd_scaled, std) {\r\n  std$y_sd * sd_scaled\r\n}\r\n\r\n\r\n\r\n# --------------- box-cox -------------------------------\r\nboxcox_transform <- function(y, lambda) {\r\n  if (any(y <= 0)) stop(\"Box-Cox requires y > 0\")\r\n  if (abs(lambda) < 1e-8) {\r\n    log(y)\r\n  } else {\r\n    (y^lambda - 1) / lambda\r\n  }\r\n}\r\nboxcox_inverse <- function(z, lambda) {\r\n  if (abs(lambda) < 1e-8) {\r\n    exp(z)\r\n  } else {\r\n    pmax(lambda * z + 1, 0)^(1 / lambda)\r\n  }\r\n}\r\n\r\n# ------ function to detect boxcox usage ----------------------\r\nuse_boxcox <- function(lambda) is.numeric(lambda) && length(lambda) == 1L && is.finite(lambda)\r\n\r\n# Identity-safe inverse (Box–Cox OFF => identity)\r\ninv_y <- function(z, lambda = NULL) {\r\n  if (use_boxcox(lambda)) boxcox_inverse(z, lambda) else z\r\n}\r\n\r\n# Optional forward transform (Box–Cox OFF => identity)\r\nfwd_y <- function(y, lambda = NULL) {\r\n  if (use_boxcox(lambda)) boxcox_transform(y, lambda) else y\r\n}\r\n","type":"text"},{"name":"R/utils.R","content":"# -----------------------------\r\n# Helpers: parsing & utilities\r\n# -----------------------------\r\n\r\nnormalize_sheet_name <- function(x) tolower(gsub(\"\\\\s+\", \"\", x))\r\n\r\nget_cat_levels <- function(def_row) {\r\n  lev <- c(def_row$Min_raw[1], def_row$Standard_raw[1], def_row$Max_raw[1])\r\n  lev <- lev[!is.na(lev) & trimws(lev) != \"\"]\r\n  unique(lev)\r\n}\r\n\r\n\r\nparse_purpose <- function(p) {\r\n  p <- trimws(as.character(p))\r\n  if (is.na(p) || p == \"\") return(list(type = \"none\", op = NA, value = NA_real_))\r\n  p2 <- gsub(\"\\\\s+\", \"\", p)\r\n  \r\n  if (grepl(\"^>=\", p2)) return(list(type = \"bound\", op = \">=\", value = as.numeric(sub(\"^>=\", \"\", p2))))\r\n  if (grepl(\"^<=\", p2)) return(list(type = \"bound\", op = \"<=\", value = as.numeric(sub(\"^<=\", \"\", p2))))\r\n  if (grepl(\"^>\", p2))  return(list(type = \"bound\", op = \">\",  value = as.numeric(sub(\"^>\",  \"\", p2))))\r\n  if (grepl(\"^<\", p2))  return(list(type = \"bound\", op = \"<\",  value = as.numeric(sub(\"^<\",  \"\", p2))))\r\n  \r\n  if (grepl(\"^[+-]?[0-9.]+([eE][+-]?[0-9]+)?$\", p2)) {\r\n    return(list(type = \"target\", op = \"=\", value = as.numeric(p2)))\r\n  }\r\n  list(type = \"unknown\", op = NA, value = NA_real_)\r\n}\r\n\r\ndesirability_1d <- function(y, purpose, y_min, y_max) {\r\n  pp <- parse_purpose(purpose)\r\n  if (pp$type == \"none\" || pp$type == \"unknown\") return(rep(NA_real_, length(y)))\r\n  \r\n  y <- as.numeric(y)\r\n  y_min <- as.numeric(y_min); y_max <- as.numeric(y_max)\r\n  if (!is.finite(y_min) || !is.finite(y_max) || y_max <= y_min) {\r\n    y_min <- min(y, na.rm = TRUE); y_max <- max(y, na.rm = TRUE)\r\n    if (!is.finite(y_min) || !is.finite(y_max) || y_max <= y_min) return(rep(NA_real_, length(y)))\r\n  }\r\n  \r\n  if (pp$type == \"bound\") {\r\n    thr <- pp$value\r\n    if (pp$op %in% c(\">\", \">=\")) {\r\n      d <- (y - thr) / (y_max - thr)\r\n      d[y < thr] <- 0\r\n      return(pmin(pmax(d, 0), 1))\r\n    }\r\n    if (pp$op %in% c(\"<\", \"<=\")) {\r\n      d <- (thr - y) / (thr - y_min)\r\n      d[y > thr] <- 0\r\n      return(pmin(pmax(d, 0), 1))\r\n    }\r\n  }\r\n  rep(NA_real_, length(y))\r\n}\r\n\r\nsample_from_definition <- function(n, Xnames, def2, n_grid_default = 20) {\r\n  \r\n  idx <- match(Xnames, def2$Parameter)\r\n  mins <- as.numeric(def2$min[idx])\r\n  maxs <- as.numeric(def2$max[idx])\r\n  ints <- as.numeric(def2$Interval[idx])\r\n  \r\n  X <- matrix(NA_real_, nrow = n, ncol = length(Xnames))\r\n  colnames(X) <- Xnames\r\n  \r\n  for (j in seq_along(Xnames)) {\r\n    \r\n    mn <- mins[j]\r\n    mx <- maxs[j]\r\n    h  <- ints[j]\r\n    \r\n    # safety check\r\n    if (!is.finite(mn) || !is.finite(mx) || mx <= mn) {\r\n      stop(\"Invalid min/max for parameter: \", Xnames[j])\r\n    }\r\n    \r\n    # ---- grid generation ----\r\n    if (is.na(h) || !is.finite(h) || h <= 0) {\r\n      # Interval未指定 → 20分割グリッド\r\n      lev <- seq(mn, mx, length.out = n_grid_default)\r\n    } else {\r\n      # Interval指定あり\r\n      lev <- seq(mn, mx, by = h)\r\n      \r\n      # もしbyでmaxに届かないならmaxも追加\r\n      if (max(lev) < mx) {\r\n        lev <- c(lev, mx)\r\n      }\r\n    }\r\n    \r\n    lev <- unique(lev)\r\n    \r\n    # ---- sampling from grid ----\r\n    if (length(lev) >= n) {\r\n      X[, j] <- sample(lev, n, replace = FALSE)\r\n    } else {\r\n      X[, j] <- sample(lev, n, replace = TRUE)\r\n    }\r\n  }\r\n  \r\n  as.data.frame(X)\r\n}\r\n\r\n\r\n# ---- prediction wrapper (raw X -> predict mean/var on original y scale) ----\r\npredict_fun <- function(fit_wrap, Xraw_new) {\r\n  if (!is.list(fit_wrap) || is.null(fit_wrap$fit) || is.null(fit_wrap$std)) {\r\n    stop(\"Model is not fitted yet. Click 'Fit model' first.\")\r\n  }\r\n  fit    <- fit_wrap$fit\r\n  std    <- fit_wrap$std\r\n  lambda <- fit_wrap$lambda\r\n  \r\n  Xraw_new <- as.matrix(Xraw_new)\r\n  \r\n  # build Xnew(with intercept) & Znew(raw)\r\n  Xnew <- cbind(1, Xraw_new)\r\n  Znew <- Xraw_new\r\n  \r\n  new_s <- standardize_apply(Xnew, Znew, std)\r\n  \r\n  pr_s <- predict_semiparam_bayes(\r\n    fit,\r\n    Xnew = new_s$X,\r\n    Znew = new_s$Z,\r\n    Z_cat_new = NULL,\r\n    return_components = FALSE\r\n  )\r\n  \r\n  mu_s <- as.numeric(pr_s$mean)\r\n  v_s  <- as.numeric(pr_s$var)\r\n  sd_s <- sqrt(pmax(v_s, 0))\r\n  \r\n  mu <- destandardize_y(mu_s, std)\r\n  sd <- destandardize_y_sd(sd_s, std)\r\n  \r\n  if (!is.null(lambda) && exists(\"inv_y\", mode = \"function\")) {\r\n    mu <- inv_y(mu, lambda = lambda)\r\n    # sd の厳密な逆変換は今は省略（lambda=NULL前提なら問題なし）\r\n  }\r\n  \r\n  list(mean = mu, var = sd^2, mean_s = mu_s, sd_s = sd_s)\r\n}\r\n\r\n\r\nmake_grid_1d <- function(x_min, x_max, interval, max_n = 20) {\r\n  \r\n  if (!is.finite(x_min) || !is.finite(x_max) || x_max <= x_min) {\r\n    stop(\"Invalid range.\")\r\n  }\r\n  \r\n  # interval無効 → 20分割\r\n  if (is.na(interval) || !is.finite(interval) || interval <= 0) {\r\n    return(seq(x_min, x_max, length.out = max_n))\r\n  }\r\n  \r\n  # intervalあり\r\n  g <- seq(x_min, x_max, by = interval)\r\n  \r\n  # 点数が多すぎる場合は間引く\r\n  if (length(g) > max_n) {\r\n    idx <- unique(round(seq(1, length(g), length.out = max_n)))\r\n    g <- g[idx]\r\n  }\r\n  \r\n  return(g)\r\n}\r\n","type":"text"},{"name":"template.xlsx","content":"UEsDBBQABgAIAAAAIQASGN7dZAEAABgFAAATAAgCW0NvbnRlbnRfVHlwZXNdLnhtbCCiBAIo\noAACAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAADElM9uwjAMxu+T9g5VrlMb4DBNE4XD/hw3\npLEHyBpDI9Ikig2Dt58bYJqmDoRA2qVRG/v7fnFjD8frxmYriGi8K0W/6IkMXOW1cfNSvE+f\n8zuRISmnlfUOSrEBFOPR9dVwugmAGWc7LEVNFO6lxKqGRmHhAzjemfnYKOLXOJdBVQs1Bzno\n9W5l5R2Bo5xaDTEaPsJMLS1lT2v+vCWJYFFkD9vA1qsUKgRrKkVMKldO/3LJdw4FZ6YYrE3A\nG8YQstOh3fnbYJf3yqWJRkM2UZFeVMMYcm3lp4+LD+8XxWGRDko/m5kKtK+WDVegwBBBaawB\nqLFFWotGGbfnPuCfglGmpX9hkPZ8SfhEjsE/cRDfO5DpeX4pksyRgyNtLOClf38SPeZcqwj6\njSJ36MUBfmof4uD7O4k+IHdyhNOrsG/VNjsPLASRDHw3a9el/3bkKXB22aGdMxp0h7dMc230\nBQAA//8DAFBLAwQUAAYACAAAACEAtVUwI/QAAABMAgAACwAIAl9yZWxzLy5yZWxzIKIEAiig\nAAIAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAKySTU/DMAyG70j8h8j31d2QEEJLd0FIuyFU\nfoBJ3A+1jaMkG92/JxwQVBqDA0d/vX78ytvdPI3qyCH24jSsixIUOyO2d62Gl/pxdQcqJnKW\nRnGs4cQRdtX11faZR0p5KHa9jyqruKihS8nfI0bT8USxEM8uVxoJE6UchhY9mYFaxk1Z3mL4\nrgHVQlPtrYawtzeg6pPPm3/XlqbpDT+IOUzs0pkVyHNiZ9mufMhsIfX5GlVTaDlpsGKecjoi\neV9kbMDzRJu/E/18LU6cyFIiNBL4Ms9HxyWg9X9atDTxy515xDcJw6vI8MmCix+o3gEAAP//\nAwBQSwMEFAAGAAgAAAAhAPOiffC2AwAA0QgAAA8AAAB4bC93b3JrYm9vay54bWysVc1u4zYQ\nvhfoOwi6KxL1Z0uIsrAsCQ2Q7AZZb3IxENASZRGRRJWiYgfBXtaH9g36GD33efwiHco/iddF\n4WYbOKRIjj59M/PN8PzDsiqVJ8JbyupARWeGqpA6ZRmt54H6ZZJoQ1VpBa4zXLKaBOozadUP\nFz//dL5g/HHG2KMCAHUbqIUQja/rbVqQCrdnrCE1nOSMV1jAks/1tuEEZ21BiKhK3TQMV68w\nrdUNgs9PwWB5TlMSsbSrSC02IJyUWAD9tqBNu0Or0lPgKswfu0ZLWdUAxIyWVDz3oKpSpf7l\nvGYcz0pwe4kcZcnh58I/MmAwd1+Co6NPVTTlrGW5OANofUP6yH9k6AgdhGB5HIPTkGydkycq\nc7hnxd13snL3WO4rGDJ+GA2BtHqt+BC8d6I5e26menGe05LcbaSr4Kb5iCuZqVJVStyKOKOC\nZIE6gCVbkIMN3jVhR0s4NT3XHKr6xV7ON1zJSI67UkxAyDt4qAzX9UxHWoIwRqUgvMaCjFkt\nQIdbv35Ucz32uGCgcOWW/NpRTqCwQF/gK4w49fGsvcGiUDpeBurYn35pwf0pVOa8mH6qScTp\nE5muV7+tv/21/vbnevX7erVar/6YvtEqPi6M/6BWnMoQ6BCDDc/N8/fxALrc3ynyRnAFni+j\nK8jKZ/wEOQIlZNsSvoQkIOuhTrmPHl5cG3kjYxRpyAstzbbDWAutONTskRE7IwuF4zj6Cs5w\n108Z7kSxTb+EDlQbcn10dI2XuxNk+B3NXmm8GNs/Tc7fDbuzr9Jh2ejuKFm0r0KRS2V5T+uM\nLQJVQ1Lez4fLRX94TzNRgJOebYLJZu8XQucFMEaGZcAmTgUkboJnsCNdMCXPQH0Zjj2UIAdp\nI9sba3Zs29ooHsBTYoUxRMSL0ajnp78h2DdYINrPSt0XRURyWlPZJKGbywbch11VuC+/wy8z\nJL08eAML/MYWut3e1uwlsPtMissUikZOPaiHDNOTFrI6b0nK4HJ5BgNOGkz5FcMy4fKcLMVV\nK/oZ9EzBXWQbo4Hh2ZoRW45mDz1TG9qWqY3tyIydQRzFoSOzLy8c//9ou31Z+bubTHpRYC4m\nHKePcP/dkjzELci1p6sD37dkQ2cYGhZQtBOUaKBbQwtD19acKLGcAYrGsZO8kpXhyd/Z9IZ6\n/zbBooOGIHtBv/blmGx395v5ZmOb94PK9m8jGfft2/9m+Bm8L8mJxsndiYbjj9eT6xNtr+LJ\nw33SC+0fvd1kQ469hvRdDi/+BgAA//8DAFBLAwQUAAYACAAAACEASqmmYfoAAABHAwAAGgAI\nAXhsL19yZWxzL3dvcmtib29rLnhtbC5yZWxzIKIEASigAAEAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAvJLNasQwDITvhb6D0b1xkv5Qyjp7KYW9ttsHMLESh01s\nY6k/efualO42sKSX0KMkNPMxzGb7OfTiHSN13ikoshwEutqbzrUKXvdPV/cgiLUzuvcOFYxI\nsK0uLzbP2GtOT2S7QCKpOFJgmcODlFRbHDRlPqBLl8bHQXMaYyuDrg+6RVnm+Z2MvzWgmmmK\nnVEQd+YaxH4Myflvbd80XY2Pvn4b0PEZC8mJC5Ogji2ygmn8XhZZAgV5nqFck+HDxwNZRD5x\nHFckp0u5BFP8M8xiMrdrwpDVEc0Lx1Q+OqUzWy8lc7MqDI996vqxKzTNP/ZyVv/qCwAA//8D\nAFBLAwQUAAYACAAAACEAUvGaT6cDAAAtCgAAGAAAAHhsL3dvcmtzaGVldHMvc2hlZXQxLnht\nbLRWbY+jNhD+Xun+A+Lz8Q55U5JTEsJ1P5xUVe31s9eYYK3BnG2SXVX97x3jhAC7qrYrXZTE\nZoZ5PM94POP1l+eKWWciJOX1xg5c37ZIjXlO69PG/vOPzFnYllSozhHjNdnYL0TaX7affllf\nuHiSJSHKAoRabuxSqWbleRKXpELS5Q2pQVNwUSEFj+LkyUYQlHdGFfNC3595FaK1bRBW4j0Y\nvCgoJinHbUVqZUAEYUiB/7KkjbyhVfg9cBUST23jYF41APFIGVUvHahtVXj1cKq5QI8MeD8H\nMcLWs4BvCL/otkwnf7VSRbHgkhfKBWTP+Pya/tJbegj3SK/5vwsmiD1BzlRv4B0q/JhLQdJj\nhXew6INgsx5Mh0usWppv7L+TLF6Ecz915mEaO/Filzi7uT93/Cibz/ap7y+y5B97u84p7LBm\nZQlSbOxdsPqa2N523eXPd0oucjC3dDo+cv6kFQ+wjA8IkjCCdWJYCIYzORDGNvZRZ/SPDhOm\nAOj1iMP5DT3rEvg3YeWkQC1Tv/PLr4SeSgWnBZC6/V/lLymRGBISFnaTxB99Yr0I5gwQ4d+q\nKBy0BPILPXfjheaqBDAwXIR+FISgeyRSZVQvYVu4lYpXf13fumIZlNkVBca3UP7Dcn61hPFm\nOXP9fv3Xlp4h0IUqRQpt14JfLEhZ8FA2SBeAYAVo74oHBEKb7sAWOErYqvM2WHtniD++6vZD\n3XKsOwx1i7EuHermY91xqJuNddnIlwno16Ey6g09CEEfBzgvH44D2PZx8CdxCLvoOOEkBEY8\nCVpqpPGE9hA+mdA2Fr57RxqxgoM7ZNVlfeJChpoM6U/C/9x4gO0JT7zdRx3hSRgORjrla6ST\n2ByH6FO+V3T3bjPiG/8cvgB7T/RJ5u3jNwkb6ZSwkU4Jj+Dvh2XEDPbsw/kJtr37k7X3yVve\np0Y69XOIM9kYqO2DEN0PruFgSrSpO00JFxFFMZTkgtdKF/tAV8UcqtJ3xCiM+i5gYd7qehzo\nVjJSWeqlgY7OqFS2hRjjlz1D9ZMpZSW/PNRNq74RKdEJXtP1DYRHIbgYCa8tJFwdwfW+ux2O\nWTxbHAJnt0x2ThxGR2cZ7CNn6SdBcjhkhyiJdXfT96KWoWBrYyBB65a38rOFkSInLihGzF57\n/Ttrb8wA6uSE7XbdgLffkDhRoM5I0XUiqMfCtCrfhbnije5Pc91guIKmcnsq4VpGoCD7Lhyd\ngnN1e9Ddsb/obf8FAAD//wMAUEsDBBQABgAIAAAAIQCHB42w8wIAAMQIAAAYAAAAeGwvd29y\na3NoZWV0cy9zaGVldDIueG1spJbbjtowEIbvK/UdIt+HnEOCgNVCQO1Fpaqne2McsDaJU9vA\nrqq+eycxJGCohNgIpGTG84+/zHiU8dNrWVh7KiTj1QR5AxdZtCJ8zarNBP38sbQTZEmFqzUu\neEUn6I1K9DT9+GF84OJFbilVFihUcoK2StUjx5FkS0ssB7ymFXhyLkqs4FFsHFkLitdtUFk4\nvuvGTolZhbTCSNyjwfOcEZpxsitppbSIoAVWsH+5ZbU8qZXkHrkSi5ddbRNe1iCxYgVTb60o\nskoy+rypuMCrArhfvRAT61XAz4d/cErT2q8ylYwILnmuBqDs6D1f46dO6mDSKV3z3yXjhY6g\ne9YUsJfyH9uSF3Vafi8WPCgWd2LN6xKjHVtP0J8ojPwgCmb2fLmY2aEbJHYaxYHtL5/DNJv5\nyyCe/0XT8ZpBhRsqS9B8gp690SJGznTc9s8vRg/y7N5SePWdFpQoCjk8ZDXtueL8pVn4GUwu\nKMp2QaOIiWJ7OqdFMUHZEDr8d5sDbiGB02U4vz9lW7YN/VVYa5rjXaG+8cMnyjZbBWnhrLT9\nMFq/ZVQSaFBIPIgi9+IKO4oMKzwdC36woPawaVnj5iR5o+hOoemYNKHPEAupJDDup547dvaw\nc3J0zs6dhm9+7gsv47IL0fjSuTh3+p3PAZYOCDroYSCI7YE8A8hvOW3DPNdmw5rdtC6OEsHA\nTaIkjd30eCW3UaB/H0aB2B6lf1Vt4WaBRoEmuWSca4cJc9O66ESSxPPTMD7BpOltmvAdNBDb\n0wRGYcKWxuwxbTVRbloX2mq7g6GXRlHidyj/KQwclIcLA7E9itH8s0ijXNVF202Y42rjjJhr\nL05H/I6dQ2y/c6NzZrGeAkY/3bRm2mo0JYzZZo5AT3qePwy7s5H2mTSJHpR6iNVb+DxQjMBg\nzHmlmpHrNXOuxhv6BYsNq6RV0LwdiDBwhZ6YUGdA4XUzJodQjxVXipenpy18LVAYb+4AzlDO\nuTo9NEO6+/6Y/gMAAP//AwBQSwMEFAAGAAgAAAAhAKgDJRpaBwAAyiAAABMAAAB4bC90aGVt\nZS90aGVtZTEueG1s7Flbixs3FH4v9D8M8+74NuPLEm/wNdtkNwlZJyWPWlv2aFczMpK8G1MC\nJQuFvhQKaelLS9/6UEoDLbSUQn/MQkIvP6JHmrFHWsvNpZvSll3D4pG/c/TpnKOjM0dXrz2M\nqXeMuSAsafnlKyXfw8mIjUkybfn3hoNCw/eERMkYUZbglr/Awr+2/fZbV9GWjHCMPZBPxBZq\n+ZGUs61iUYxgGIkrbIYT+G3CeIwkPPJpcczRCeiNabFSKtWKMSKJ7yUoBrW3JxMywt7Z6Qdn\npz+fnX7hby8n6FOYJZFCDYwo31fqsSWlseOjskKIhehS7h0j2vJhrjE7GeKH0vcoEhJ+aPkl\n/ecXt68W0VYmROUGWUNuoP8yuUxgfFTRc/LpwWrSIAiDWnulXwOoXMf16/1av7bSpwFoNIKV\nplxsnfVKN8iwBij96tDdq/eqZQtv6K+ucW6H6mPhNSjVH6zhB4MuWNHCa1CKD9fwYafZ6dn6\nNSjF19bw9VK7F9Qt/RoUUZIcraFLYa3aXa52BZkwuuOEN8NgUK9kynMURMMqutQUE5bITbEW\no0PGBwBQQIokSTy5mOEJGkEkdxElB5x4u2QaQeDNUMIEDJcqpUGpCv/VJ9DftEfRFkaGtOIF\nTMTakOLjiREnM9nyb4BW34A8+/HHs8ffnz3+4ez09Ozxt9ncWpUlt4OSqSn3+1cf//H5+95v\n3335+5NP0qnP44WJf/7Nh89/+uWv1MOKc1M8+/Tp8++fPvvso1+/fuLQ3ubowIQPSYyFdwuf\neHdZDAt08McH/NUkhhEilgSKQLdDdV9GFvDWAlEXroNtE97nkGVcwOvzQ4vrfsTnkjhmvhnF\nFnCPMdph3GmAm2ouw8LDeTJ1T87nJu4uQseuubsosRzcn88gvRKXym6ELZp3KEokmuIES0/9\nxo4wdqzuASGWXffIiDPBJtJ7QLwOIk6TDMmBFUi50A6JwS8LF0FwtWWbvfteh1HXqnv42EbC\ntkDUQX6IqWXG62guUexSOUQxNQ2+i2TkIrm/4CMT1xcSPD3FlHn9MRbCJXObw3oNp9+EDON2\n+x5dxDaSS3Lk0rmLGDORPXbUjVA8c3ImSWRi3xFHEKLIu8OkC77H7B2insEPKNno7vsEW+5+\ncSK4B8nVpJQHiPplzh2+vI6ZvR8XdIKwK8u0eWxl1zYnzujozKdWaO9iTNEJGmPs3XvHwaDD\nZpbNc9I3IsgqO9gVWDeQHavqOcECe7quWU+Ru0RYIbuPp2wDn73FucSzQEmM+CbNt8DrVujC\nKedMpbfp6MgE3iJQAkK8OI1yW4AOI7j7m7TeiZB1dqln4Y7XBbf89zJ7DPbl4avuS5DBrywD\nif2lbTNE1JogD5ghggLDlW5BxHJ/LqLOVS02d8pN7E2buwEKI6veiUnywuLnXNkT/jNlj7uA\nuYCCx63475Q6m1LKzrkCZxPuP1jW9NA8uYPhJFnPWZdVzWVV4//vq5pNe/mylrmsZS5rGdfb\n1xupZfLyBSqbvMujez7xxpbPhFC6LxcU7wrd9RHwRjMewKBuR+me5KoFOIvga9ZgsnBTjrSM\nx5l8l8hoP0IzaA2VdQNzKjLVU+HNmICOkR7W7VR8TrfuO83jPTZOO53lsupqpiYUSObjpXA1\nDl0qmaJr9bx7t1Kv+6FT3WVdElCyr0LCmMwmUXWQqC8HwQt/RUKv7EJYNB0sGkr90lVLL65M\nAdRWXoFXbg9e1Ft+GKQdZGjGQXk+Vn5Km8lL7yrnXKinNxmTmhEAJfYyAnJPNxXXjctTq0tD\n7SU8bZEwws0mYYRhBC/CWXSaLfeL9HUzd6lFT5liuRtyGvXGm/C1SiLncgNNzExBE++k5deq\nIdysjNCs5U+gYwxf4xnEjlBvXYhO4eplJHm64V8ns8y4kD0kotTgOumk2SAmEnOPkrjlq+Wv\nooEmOodobuUKJIR/LbkmpJV/Gzlwuu1kPJngkTTdbowoS6ePkOHTXOH8VYu/PlhJsjm4ez8a\nn3gHdM7vIgixsF5WBhwTARcH5dSaYwI3YatElsffuYMpS7vmVZSOoXQc0VmEshPFTOYpXCfR\nFR39tLKB8ZStGQy6bsKDqTpg//ap++KjWlnOSJr5mWllFXVqupPpmzvkDVb5IWqxSlO3fqcW\nea5rLnMdBKrzlHjBqfsSB4JBLZ/MoqYYr6dhlbOzUZvaBRYEhiVqG+y2OiOclnjdkx/kzket\nOiCWdaUOfH1tbt5qs4NDSB49uD+cUym0K+HOmiMo+tIbyDRtwBZ5KLMaEb55c05a/nulsB10\nK2G3UGqE/UJQDUqFRtiuFtphWC33w3Kp16k8goNFRnE5TK/sB3CFQRfZxb0eX7u8j5e3NFdG\nLC4yfTlf1MT15X254rq8H6qbed8jkHTeq1UGzWqzUys0q+1BIeh1GoVmt9Yp9Grdem/Q64aN\n5uCR7x1rcNCudoNav1GolbvdQlArKfqNZqEeVCrtoN5u9IP2o6yMgZWn6SOzBZhX89r+EwAA\n//8DAFBLAwQUAAYACAAAACEAmN0xmfMCAAAjBwAADQAAAHhsL3N0eWxlcy54bWy0Vc1q20AQ\nvhf6DsveFf3Ecm0jKdRxBIEWCkmh17W0spfsj9ldp3JLL8k7FPoGvfVSaOjrGPIcnZXkWCHQ\nn4RerN2Z3W++mW92nBzVgqNLqg1TMsXhQYARlYUqmVyk+O157o0wMpbIknAlaYo31OCj7Pmz\nxNgNp2dLSi0CCGlSvLR2NfF9UyypIOZAragET6W0IBa2euGblaakNO6S4H4UBENfECZxizAR\nxd+ACKIv1iuvUGJFLJszzuymwcJIFJPThVSazDlQrcMBKVAdDnWEar0L0lgfxBGs0Mqoyh4A\nrq+qihX0Id2xP/ZJsUcC5MchhbEfRPdyr/UjkQa+ppfMyYezpFLSGlSotbQpjoCoK8HkQqr3\nMncuULg7lSXmA7okHCwh9rOkUFxpZEE6qFxjkUTQ9sTtzc326vv26sf2+np79c0dr4hgfNO6\no+b+kmgDvdBCRiNnazqhwxAMdHFG33Fsme45DJ3n/wZs4hoIzDjvlag1ZAn0kqVa5uBF3fp8\ns4JaSGj7lje4/nh6ockmjOLeBb8JmCVzpUt4ZjtxnA6tKUs4rSzkr9li6b5WreB3rqyFVsyS\nkpGFkoS72u1udAtIp6Ccn7mn+K66h11XSK5FLuxpmWJ41K7quyUk0i1bvHaTJYSzhRRUgopU\nW1a47ihgS1vh6goY9OO10Z8cGNXVvzKAmL3U7yV+RxC5fkrx7dcvtz8/w1PogqD5mnHLZBvS\nFfXuBmCW9b6MgVPRulnSFPguClSzpBVZc3t+50zxfv2almwt4PV1p96wS2UbiBTv16+c2mHT\n+LS2rwy8CfiitWYp/ngyfTGeneSRNwqmI29wSGNvHE9nXjw4ns5m+TiIguNPvYn2hHnWDOAs\ngUkxMRymnu6S7cif7W0p7m1a+k2fA+0+93E0DF7GYeDlh0HoDYZk5I2Gh7GXx2E0Gw6mJ3Ee\n97jHj5x7gR+G7QR15OOJZYJyJnda7RTqW0Ek2P4mCX+nhL//d8t+AQAA//8DAFBLAwQUAAYA\nCAAAACEATFX04SYBAACPAwAAFAAAAHhsL3NoYXJlZFN0cmluZ3MueG1sjFOxasMwEN0L/Qeh\noVsjJ21DaWVlKBQyBAJNIRmFdbEP7JMrnUPy91XjDCFdNOrpvXe6dye9OHatOECI6KmU00kh\nBVDlHVJdyu/N5+OrFJEtOdt6glKeIMqFub/TMbJIWoqlbJj7N6Vi1UBn48T3QOlm70NnOR1D\nrWIfwLrYAHDXqllRzFVnkaSo/EBcytlcioHwZ4CPC1BIoyMazWY71YqN7ptUn7FaB7H3xEuX\nXiuV0eqPNTLXNtgOGEKuYJdvPYTeR8g13s5ymVXqBWnwQzwrrrrZnPrseit7zC34dR5mcLn8\nFVIuFbNN0WUnj27M8ioZdE+3YaF7/g+93ELbUZexSg81v4/yDPKS0s4dbJs9c8tQ+4DVRXJu\nTaUPZX4BAAD//wMAUEsDBBQABgAIAAAAIQD3U1xgXgEAAHECAAARAAgBZG9jUHJvcHMvY29y\nZS54bWwgogQBKKAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACM\nkjFOwzAYhXck7hB5T5y0akBWkkqAOlEJiSIQm2X/bSMSx7INaTfgEkwcgIkRBo4DCG6Bk7Qh\nqB0Y7ff+z+/9cjRc5JlzA0qnhYhR4PnIAcEKnopZjM4mI3cfOdpQwWlWCIjREjQaJrs7EZOE\nFQpOVCFBmRS0Y0lCEyZjNDdGEow1m0NOtWcdworTQuXU2KOaYUnZFZ0B7vl+iHMwlFNDcQV0\nZUtEKyRnLVJeq6wGcIYhgxyE0TjwAvzrNaByvXWgVjrOPDVLaTut4nbZnDVi617otDWWZemV\n/TqGzR/gi/HxaV3VTUW1KwYoiTgjTAE1hUq+797eX2+/Xp6dz4enj8f7CHfEapEZ1WZsdz5N\ngR8st/g3PZZf12keAe7YgKSps1bO+4dHkxFKen4vdP2eGwQTf58EIRmEl1WEP/NV4OYiXwX5\nD3FQEf09Muh3iGtAEuGNT5L8AAAA//8DAFBLAwQUAAYACAAAACEA4ilugaMBAAA2AwAAEAAI\nAWRvY1Byb3BzL2FwcC54bWwgogQBKKAAAQAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\nAAAAAAAAAAAAAACck7Fu2zAQhvcCeQeBe0zFKYLCoBgUdoIMLWrATnaWOtlEJZIgL4LdMV76\nNhm79G38IjlKiCI3Q4Fu/91/+vXpSInrXVNnLYRonC3YxSRnGVjtSmM3Bbtf355/YllEZUtV\nOwsF20Nk1/Lsg1gG5yGggZhRhI0F2yL6GedRb6FRcUK2JadyoVFIZdhwV1VGw8LpxwYs8mme\nX3HYIdgSynM/BLI+cdbi/4aWTie++LDeewKW4rP3tdEK6SvlV6ODi67C7GanoRZ8bAqiW4F+\nDAb3Mhd8XIqVVjXMKVhWqo4g+FtD3IFKS1sqE6IULc5a0OhCFs1PWtuUZd9VhIRTsFYFoywS\nVhrri07XPmKQx8Pz8fDn+PR8fPqdxOGX4DTYm50cPzPW5qOcdgMkTgdTQA9Exinq2mAN8Vu1\nVAH/Rd4x9Nw9zgIqY01a65hxoF0oVO/gu70Qxl8vnrvGK7snY1BfjP0R7/3aUQ687vy0KVZb\nFaCkYxrOZGiIO1p3qFPIfKvsBsrXmfdGuiEP/W8gL64m+WVOhz/qCf524eULAAAA//8DAFBL\nAQItABQABgAIAAAAIQASGN7dZAEAABgFAAATAAAAAAAAAAAAAAAAAAAAAABbQ29udGVudF9U\neXBlc10ueG1sUEsBAi0AFAAGAAgAAAAhALVVMCP0AAAATAIAAAsAAAAAAAAAAAAAAAAAnQMA\nAF9yZWxzLy5yZWxzUEsBAi0AFAAGAAgAAAAhAPOiffC2AwAA0QgAAA8AAAAAAAAAAAAAAAAA\nwgYAAHhsL3dvcmtib29rLnhtbFBLAQItABQABgAIAAAAIQBKqaZh+gAAAEcDAAAaAAAAAAAA\nAAAAAAAAAKUKAAB4bC9fcmVscy93b3JrYm9vay54bWwucmVsc1BLAQItABQABgAIAAAAIQBS\n8ZpPpwMAAC0KAAAYAAAAAAAAAAAAAAAAAN8MAAB4bC93b3Jrc2hlZXRzL3NoZWV0MS54bWxQ\nSwECLQAUAAYACAAAACEAhweNsPMCAADECAAAGAAAAAAAAAAAAAAAAAC8EAAAeGwvd29ya3No\nZWV0cy9zaGVldDIueG1sUEsBAi0AFAAGAAgAAAAhAKgDJRpaBwAAyiAAABMAAAAAAAAAAAAA\nAAAA5RMAAHhsL3RoZW1lL3RoZW1lMS54bWxQSwECLQAUAAYACAAAACEAmN0xmfMCAAAjBwAA\nDQAAAAAAAAAAAAAAAABwGwAAeGwvc3R5bGVzLnhtbFBLAQItABQABgAIAAAAIQBMVfThJgEA\nAI8DAAAUAAAAAAAAAAAAAAAAAI4eAAB4bC9zaGFyZWRTdHJpbmdzLnhtbFBLAQItABQABgAI\nAAAAIQD3U1xgXgEAAHECAAARAAAAAAAAAAAAAAAAAOYfAABkb2NQcm9wcy9jb3JlLnhtbFBL\nAQItABQABgAIAAAAIQDiKW6BowEAADYDAAAQAAAAAAAAAAAAAAAAAHsiAABkb2NQcm9wcy9h\ncHAueG1sUEsFBgAAAAALAAsAxgIAAFQlAAAAAA==","type":"binary"}]
